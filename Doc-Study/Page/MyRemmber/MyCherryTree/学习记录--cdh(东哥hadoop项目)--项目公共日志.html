<!doctype html><html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <title>项目公共日志</title>
  <meta name="generator" content="CherryTree">
  <link rel="stylesheet" href="styles.css" type="text/css" />
</head>
<body><div class="main"><div class="tree">
<p><strong>Index</strong></p>
<p><a href="学习记录.html">学习记录</a></p>

<ol>
<li><a href="学习记录--Needto_Study.html">Needto Study</a></li>
<ol>
<li><a href="学习记录--Needto_Study--NeedStudy_01.html">NeedStudy_01</a></li>
</ol>
<li><a href="学习记录--Sqoop.html">Sqoop</a></li>
<ol>
<li><a href="学习记录--Sqoop--Sqoop_01.html">Sqoop_01</a></li>
<ol>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop介紹.html">Sqoop介紹</a></li>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop命令.html">Sqoop命令</a></li>
<ol>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop命令--Sqoop常用命令.html">Sqoop常用命令</a></li>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop命令--Sqoop测试命令.html">Sqoop测试命令</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--Hadoop.html">Hadoop</a></li>
<ol>
<li><a href="学习记录--Hadoop--Hadoop_介绍.html">Hadoop 介绍</a></li>
<li><a href="学习记录--Hadoop--Hadoop环境搭建.html">Hadoop环境搭建</a></li>
</ol>
<li><a href="学习记录--Linux.html">Linux</a></li>
<ol>
<li><a href="学习记录--Linux--linux_零散命令.html">linux 零散命令</a></li>
</ol>
<li><a href="学习记录--Spark.html">Spark</a></li>
<ol>
<li><a href="学习记录--Spark--Spark_介绍.html">Spark 介绍</a></li>
<li><a href="学习记录--Spark--Spark_搭建.html">Spark 搭建</a></li>
<li><a href="学习记录--Spark--Spark_RDD.html">Spark RDD </a></li>
<li><a href="学习记录--Spark--SparkSQl.html">SparkSQl</a></li>
<li><a href="学习记录--Spark--Spark_other.html">Spark other</a></li>
<ol>
<li><a href="学习记录--Spark--Spark_other--Spark_累加器.html">Spark 累加器</a></li>
</ol>
<li><a href="学习记录--Spark--Spark_每日一记.html">Spark 每日一记</a></li>
</ol>
<li><a href="学习记录--Flume.html">Flume</a></li>
<ol>
<li><a href="学习记录--Flume--Flume_介绍、架构.html">Flume 介绍、架构</a></li>
<li><a href="学习记录--Flume--Flume使用.html">Flume使用</a></li>
<ol>
<li><a href="学习记录--Flume--Flume使用--Flume_1701笔记.html">Flume 1701笔记</a></li>
</ol>
</ol>
<li><a href="学习记录--Kafka.html">Kafka</a></li>
<ol>
<li><a href="学习记录--Kafka--Kafka介绍、运行机制.html">Kafka介绍、运行机制</a></li>
</ol>
<li><a href="学习记录--Hive.html">Hive</a></li>
<ol>
<li><a href="学习记录--Hive--Hive_介绍架构.html">Hive 介绍架构</a></li>
<li><a href="学习记录--Hive--Hive_QL_语句.html">Hive QL 语句</a></li>
<li><a href="学习记录--Hive--Hive_UDF.html">Hive UDF</a></li>
<li><a href="学习记录--Hive--Hive东哥笔记.html">Hive东哥笔记</a></li>
<li><a href="学习记录--Hive--hive_装在数据的几种方式.html">hive 装在数据的几种方式</a></li>
<ol>
<li><a href="学习记录--Hive--hive_装在数据的几种方式--01.html">01</a></li>
</ol>
<li><a href="学习记录--Hive--hive的几种join.html">hive的几种join</a></li>
<ol>
<li><a href="学习记录--Hive--hive的几种join--01.html">01</a></li>
</ol>
</ol>
<li><a href="学习记录--Hbase.html">Hbase </a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记.html">Hbase 命令笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--东哥笔记.html">东哥笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--东哥笔记--hbase笔记总结.html">hbase笔记总结</a></li>
</ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_命令笔记.html">Hbase 命令笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_命令笔记--Hbase命令笔记_01.html">Hbase命令笔记_01</a></li>
</ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_API笔记.html">Hbase API笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_API笔记--Hbase_API笔记.html">Hbase API笔记</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--ELK.html">ELK</a></li>
<ol>
<li><a href="学习记录--ELK--ELK总结.html">ELK总结</a></li>
<li><a href="学习记录--ELK--ELK_博客.html">ELK 博客</a></li>
</ol>
<li><a href="学习记录--ETL.html">ETL</a></li>
<ol>
<li><a href="学习记录--ETL--ETL总结.html">ETL总结</a></li>
<li><a href="学习记录--ETL--ETL_博客.html">ETL 博客</a></li>
</ol>
<li><a href="学习记录--服务器云计算.html">服务器云计算</a></li>
<ol>
<li><a href="学习记录--服务器云计算--简单总结.html">简单总结</a></li>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置.html">linux 添加ss 的配置</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--我的.html">我的</a></li>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令.html">服务器阶段的命令</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--下载安装命令.html">下载安装命令</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--下载安装命令--wget.html">wget</a></li>
</ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--其他配置.html">其他配置</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--其他配置--配置命令.html">配置命令</a></li>
</ol>
</ol>
</ol>
</ol>
<li><a href="学习记录--面试方面.html">面试方面</a></li>
<ol>
<li><a href="学习记录--面试方面--代码准备.html">代码准备</a></li>
<ol>
<li><a href="学习记录--面试方面--代码准备--代码准备_01.html">代码准备_01</a></li>
<ol>
<li><a href="学习记录--面试方面--代码准备--代码准备_01--worldCount准备.html">worldCount准备</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--每天记录.html">每天记录</a></li>
<ol>
<li><a href="学习记录--每天记录--今日整理待整理.html">今日整理待整理</a></li>
</ol>
<li><a href="学习记录--cdh(东哥hadoop项目).html">cdh(东哥hadoop项目)</a></li>
<ol>
<li><a href="学习记录--cdh(东哥hadoop项目)--cdh配置.html">cdh配置</a></li>
<ol>
<li><a href="学习记录--cdh(东哥hadoop项目)--cdh配置--cdh安装.html">cdh安装 </a></li>
<li><a href="学习记录--cdh(东哥hadoop项目)--cdh配置--cdh安装集群模式.html">cdh安装集群模式</a></li>
</ol>
<li><a href="学习记录--cdh(东哥hadoop项目)--Hadoop项目笔记.html">Hadoop项目笔记</a></li>
<li><a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html">项目公共日志</a></li>
</ol>
<li><a href="学习记录--Hadoop、spark等进程.html">Hadoop、spark等进程</a></li>
<ol>
<li><a href="学习记录--Hadoop、spark等进程--Hadoop-spakr-zookeeper-等.html">Hadoop/spakr/zookeeper/等</a></li>
</ol>
<li><a href="学习记录--其他技术.html">其他技术</a></li>
<ol>
<li><a href="学习记录--其他技术--内存与磁盘问题.html">内存与磁盘问题</a></li>
<li><a href="学习记录--其他技术--flink.html">flink</a></li>
<li><a href="学习记录--其他技术--VPN搭建.html">VPN搭建</a></li>
<ol>
<li><a href="学习记录--其他技术--VPN搭建--服务器地址pas.html">服务器地址pas</a></li>
<ol>
<li><a href="学习记录--其他技术--VPN搭建--服务器地址pas--free_IP.html">free IP</a></li>
</ol>
</ol>
<li><a href="学习记录--其他技术--人工智能.html">人工智能</a></li>
<ol>
<li><a href="学习记录--其他技术--人工智能--人工智能书单.html">人工智能书单</a></li>
<ol>
<li><a href="学习记录--其他技术--人工智能--人工智能书单--人工智能书单_01.html">人工智能书单_01</a></li>
</ol>
<li><a href="学习记录--其他技术--人工智能--人工智能算法.html">人工智能算法</a></li>
<ol>
<li><a href="学习记录--其他技术--人工智能--人工智能算法--人工智能算法——01.html">人工智能算法——01</a></li>
</ol>
</ol>
<li><a href="学习记录--其他技术--下载地址.html">下载地址</a></li>
<ol>
<li><a href="学习记录--其他技术--下载地址--创作社区.html">创作社区</a></li>
<li><a href="学习记录--其他技术--下载地址--it创作社区.html">it创作社区</a></li>
<li><a href="学习记录--其他技术--下载地址--源码解读.html">源码解读</a></li>
<li><a href="学习记录--其他技术--下载地址--复习语句总结.html">复习语句总结</a></li>
<ol>
<li><a href="学习记录--其他技术--下载地址--复习语句总结--复习语句总结.html">复习语句总结</a></li>
</ol>
</ol>
<li><a href="学习记录--其他技术--负载均衡.html">负载均衡</a></li>
<ol>
<li><a href="学习记录--其他技术--负载均衡--负载均衡_01.html">负载均衡_01</a></li>
</ol>
</ol>
<li><a href="学习记录--Phthon.html">Phthon</a></li>
<ol>
<li><a href="学习记录--Phthon--python_使用spark.html">python 使用spark</a></li>
</ol>
<li><a href="学习记录--数据结构.html">数据结构</a></li>
<ol>
<li><a href="学习记录--数据结构--数据结构1.html">数据结构1</a></li>
<ol>
<li><a href="学习记录--数据结构--数据结构1--Hash_问题.html">Hash 问题</a></li>
<li><a href="学习记录--数据结构--数据结构1--数据结构中的树.html">数据结构中的树</a></li>
<ol>
<li><a href="学习记录--数据结构--数据结构1--数据结构中的树--数据结构树是怎么遍历的.html">数据结构树是怎么遍历的</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--通信协议.html">通信协议</a></li>
<li><a href="学习记录--开发工具记录.html">开发工具记录</a></li>
<ol>
<li><a href="学习记录--开发工具记录--idea_的一些记录.html">idea 的一些记录</a></li>
<li><a href="学习记录--开发工具记录--博客地址.html">博客地址</a></li>
</ol>
<li><a href="学习记录--数据库.html">数据库</a></li>
<ol>
<li><a href="学习记录--数据库--mysql.html">mysql</a></li>
</ol></ol></div>
<div class="page"><h1><b><u>项目公共日志</u></b></h1><br />• <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h1-1">• 项目路径</a><br />• <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h1-2">• 所用命令</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-1">1 测试命令</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-2">2 Flume :</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-3">3 Hbase :</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-4">	3.2  导入到mysql 数据</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-5">4  集群上跑 </a><br />    ▪ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h3-1">4.1 yarn :错误</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-6">4  本地需注意：</a><br />    ▪ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h3-2"> 1运行注意点：</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-7"> 2 hive </a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-8">2.1 hive 创建表 </a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-9">2.2 加载数据：</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-10">2.3 项目过程执行的类</a><br />• <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h1-3">2 用户的埋点处理日志</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-11">2  prom.xml </a><br />• <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h1-4">3 项目简单记录</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-12">3.1 项目中的错误：</a><br />• <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h1-5">4  项目中的问题</a><br />• <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h1-6">•4.0  ParserLogDataRunner 中的问题</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-13">    4.1  这个ConcurrentHashMap 有什么好处吗？</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-14">4.2 clean up</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-15">4.3 crc32  是干嘛的</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-16">4.4 赋值了一个date</a><br />  ◇ <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h2-17">4.5 提交任务</a><br />• <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h1-7">4.6 ParserLogDataMapperToHdfs 种问题</a><br />• <a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html#h1-8">N other</a><br /><br /><br /><br /><br /><br /><br /><a name="h1-1"></a><h1>• 项目路径</h1><br />idea  <a href="file://D:\MyIdeWorkSpace\Transform">D:\MyIdeWorkSpace</a><br />eclipse <a href="file://E:\MyEcpliseWorkspaces\My_03">E:\MyEcpliseWorkspaces\My_03</a><br /><br /><br /><a href="file://G:\重要文件\前锋移动数据\千峰培训\每天记录\Hadoop最后项目\Day09 亚东老师的Hadoop项目\项目课件\20 浏览器PV分析\代码\bc_transform\src\main\config">G:\重要文件\前锋移动数据\千峰培训\每天记录\Hadoop最后项目\Day09 亚东老师的Hadoop项目\项目课件\20 浏览器PV分析\代码\bc_transform\src\main\config</a><br /><br /><br /><a name="h1-2"></a><h1>• 所用命令</h1><br /><a name="h2-1"></a><h2>1 测试命令</h2><br />sudo service nginx restart <br />sudo chown -R hadoop:hadoop /home/hadoop/installed/hadoop-2.5.0-cdh5.3.6/<br /><br />yarn测试：<br />		yarn ./share/hadoop/mapreduce2/hadoop-mapreduce-examples-2.5.0-cdh5.3.6.jar wordcount /test /out/00 <br /><br />安全模式离开：<br />		hdfs dfsadmin -safemode leave<br />		<br />		<br /><a name="h2-2"></a><h2>2 Flume :</h2><br /><br />flume-ng agent --conf  /home/hadoop/installed/apache-flume-1.5.0-cdh5.3.6-bin/conf/ -f /home/hadoop/installed/apache-flume-1.5.0-cdh5.3.6-bin/conf/agent.conf -n agent  -Dflume.root.logger=INFO,console &amp;		<br />		<br />		<br /><a name="h2-3"></a><a name="h2-3"></a><h2>3 Hbase :</h2><br />    生成的是  'event_logs'表  ，<br />    disable table 'event_logs'<br />    truncate 'event_logs'  <br />    //修改平台<br />    put 'event_logs' ,'row-key','info:pl','java_server'<br />    <br /><br />• 1 <br /><span style="color:#808080;">//edu.qianfeng.etl.mr.tohbase.ParserLogDataRunner  执行这一个 -d 2017-12-12  <br />// 把flume 拉hdfs logs/month=12/day=12 的数据拉倒hbase中<br />   //打开 hdfs、hbase <br /></span><span style="color:#cc7832;">public class </span>ParserLogDataRunner <span style="color:#cc7832;">implements </span>Tool{<br /><br />•  2 <br />执行Day04 的stats_User 表中插入数据<br /><span style="color:#808080;">//package edu.qianfeng.transform.mr.nu;<br />//这个执行  设置参数 -d 2017-12-12  ,并且在级群上面需要吧 hdfs，hbase 给打开<br /></span><span style="color:#cc7832;">public class </span>NewInstallUserRunner <span style="color:#cc7832;">implements </span>Tool {<br /><br />  遇到错误 ：<br />        * <br />        问题：1<br />             /tmp/.. 权限错误<br />             hdfs dfs -chmod  -R 777  /tmp <br />        <br />        exits-core  离开代码异常 打开yarn配置，并设置为true（加载集群本地的jar或者其他环境）<br /><br /><br />◇ Status_user  :<br />     - 插入之后  查询：<br />        →  scan 'event_logs',{COLUMNS =&gt; ['info:s_time','info:en','info:u_ud']}<br /><br />___<br />	<br />	<br />	<br /><a name="h2-4"></a><h2>	3.2  导入到mysql 数据 </h2><br />	core-site .xml 下方的配置文件如果没有注释，那么这里就是设置为true<br />	下面的设置参数  -d  2017-12-12<br />	<br />	<img src="images\90-1.png" alt="images\90-1.png" /><br />	<br /><img src="images\90-2.png" alt="images\90-2.png" />	<br />143 错误 内存不足？？？？？？？？<br /><img src="images\90-3.png" alt="images\90-3.png" /><br />开启历史服务<br />8088 端口查看任务进展<br /><br />101    就是conn 或者conf  俩问题，就是服务器上面没有mysql包<br /><img src="images\90-4.png" alt="images\90-4.png" /><br /><br />mr-jobhistory-daemon.sh start historyserver 		<br /><br /><img src="images\90-5.png" alt="images\90-5.png" /><br />把jar包 配置到环境变量中，<br />整体来说就是吧mysql的jar包打到jar 包中，<br />要么把mysql的jar包放到类环境变量中<br /><br /><br /><a name="h2-5"></a><h2>•   classPath </h2><br /><br />• vi ~/.bash_profile <br /># 需要吧mysql-connector-java-5.1.6-bin.jar 导入到 /usr/local/jdk1.7.0_79/jre/lib/ext/ 下面<br />export CLASSPATH=.:/usr/local/jdk.1.7.0_79/lib/tools.jar:/usr/local/jdk.1.7.0_79/lib/dt.jar:/usr/local/jdk.1.7.0_79/lib/rt.jar:/jre/lib/rt.jar:/usr/local/jdk1.7.0_79/jre/lib/ext/mysql-connector-java-5.1.31.jar<br /><br />export HADOOP_CLASSPATH=/home/hadoop/installed/hbase-0.98.6-cdh5.3.6/lib/*:classpath<br /><br /><br />• source ~/.bash_profile<br />• echo $CLASSPATH  看下<br />•  测试是否可用的配置<br />java -classpath /home/Myinputdata/HadoopTest/newToMySql.jar edu.qianfeng.util.JDBCUtil<br />然后执行你的jar包 就有sql 连接了，这就是刚才执行的问题<br />不过一般这里都是提前拉倒服务器上面<br />	<br />    如果这样配置了 jdk里面的 mysql驱动就可以删了<br />yarn jar  /home/Myinputdata/HadoopTest/newToMySql.jar edu.qianfeng.transform.mr.nu.NewInstallUserRunner -d 2017-12-12<br />	——————————————<br />	<br /><a name="h2-4"></a><a name="h2-6"></a><h2>4  集群上跑 </h2><br />        yarn jar  /home/hadoop...jar包的路径类参数 <br />		<br /><a name="h3-1"></a><h3>4.1 yarn :错误</h3><br />经常143  11 <br /><br />• vesion 52 0 就是jdk的版本不对应，打的包是1.8 的但是linux上面的是1.7 的<br />		tar -zxvf /jdk目录 <br />打包上传集群需要注意事项：<br />1. 可以在jdk 1.7里面的换成解压好的1.8 的<br />2. 注释以下文件<br /><br /><img src="images\90-6.png" alt="images\90-6.png" /><br /><br /><br /><br />flume 采集nginx的日志到  logs/12/12 下面 的日志文件	存到hdfs文件系统<br />/gpTransform/month=12/day=12，用于之后的映射hive 表 ，/hive/logs/month=12/day=12<br /><br />jar 包 Tohdfs.jar  存到hdfs上面（/gpTransform/month=12/day=12）<br />yarn jar /home/Myinputdata/HadoopTest/Tohdfs.jar edu.qianfeng.etl.mr.tohdfs.ParserLogDataToHdfsRunner -d 2017-12-12<br />		<br />		<br /><br /><br /><a name="h2-5"></a><a name="h2-7"></a><h2>4  本地需注意：</h2><br />* 配置文件在本地的话输入输出目录都不能为中文，并且配置文件不能有，都应该注释<br />输入E://....  输出  E://...<br />		<br />		<br /><a name="h3-2"></a><h3> 1运行注意点：</h3><br /> <br />    运行 transform 注意集群的jdk要设置为jdk1.8 <br /> <br /> 注意在本地的时候，要设置为true  ：<br />    所为本地也就是设置输入输出目录在本地<br />    Path inpath = <span style="color:#cc7832;">new </span>Path(<span style="color:#6a8759;">"E://hadoopdata//11"</span>)<span style="color:#cc7832;">;</span><br /><br />false:<br />    如果是在本地环境获取集群上的数据，并且把数据写入到集群上的化要设置为false，<br />    jar包在集群上跑 false<br /> <br /> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br />		<br />		<br />		<br /><a name="h2-8"></a><h2> 2 hive </h2><br /><a name="h2-9"></a><h2>2.1 hive 创建表 </h2><br /><br />hive 中没有字增长，也没有enum 枚举类型<br /><br />hive --service metastore &amp; <br /> <br /> create table if not exists u2(<br />uname string comment 'this is uname',<br />chinese int comment 'this is chinese',<br />math int,<br />english int<br />)<br />comment 'this table of u2'<br />row format delimited fields terminated by '\t'<br />lines terminated by '\n'<br />stored as textfile<br />;<br /><br />为hive表加载数据：<br />load data [local] inpath '/home/socre' [overwrite] into table u2;<br />load data inpath '/home/socre' into table u2;<br />load local data inpath '/home/u' into table u;<br /><br /><br /><br />create external table if not exists logs (<br />s_time string ,<br />en string ,<br />ver string ,<br />u_ud string ,<br />u_mid string ,<br />u_sid string ,<br />c_time string ,<br />language string ,<br />b_iev string ,<br />b_rst string ,<br />p_url string ,<br />p_ref string ,<br />tt string ,<br />pl string ,<br />o_id string ,<br />`on` string ,<br />cut string ,<br />cua string ,<br />pt string ,<br />ca string ,<br />ac string ,<br />kv_ string ,<br />du string ,<br />os string ,<br />os_v string ,<br />browser string ,<br />browser_v string ,<br />country string ,<br />province string ,<br />city string <br />)<br />partitioned by (month String ,day string)<br />row format delimited fields terminated by '\001';<br /><br /><br />——————————————————————<br /><a name="h2-10"></a><h2>2.2 加载数据：</h2><br /><br />load data inpath '/gpTransform/month=12/day=12/part-m-00000' into table logs partition(month=12,day=12);<br /><br /><a name="h2-11"></a><h2>2.3 项目过程执行的类</h2><br />• •  hive 中执行的类<br />• 1 <br /><em><span style="color:#629755;">/**<br /> * 清洗日志数据存储hdfs的驱动类<br /> * </span></em><em><strong><span style="color:#629755;">@author lyd<br /> * edu.qianfeng.etl.mr.tohdfs.ParserLogDataToHdfsRunner  执行这一个类吧数据从hdfs 中给映射到hive中<br /> * 执行过程中  传入参数  -d 2017-12-12<br /> */<br /></span></strong></em><em><strong><span style="color:#cc7832;">public class </span></strong></em><em><strong>ParserLogDataToHdfsRunner </strong></em><em><strong><span style="color:#cc7832;">implements </span></strong></em><em><strong>Tool{</strong></em><br /><br /><br />~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br /><br /><a name="h1-3"></a><h1>2 用户的埋点处理日志</h1><br /><br /><a name="h2-5"></a>1  demo2  生成的日志三种日志生成<br /><br />192.168.111.1^A1512997066.283^A192.168.111.123^A/?en=e_pv&amp;p_url=http%3A%2F%2Flocalhost%3A8080%2FGP1702-jssdk%2Fdemo2.jsp&amp;p_ref=http%3A%2F%2Flocalhost%3A8080%2FGP1702-jssdk%2Fdemo4.jsp&amp;tt=%E6%B5%8B%E8%AF%95%E9%A1%B5%E9%9D%A22&amp;ver=1&amp;pl=website&amp;sdk=js&amp;u_ud=11DD76A0-F198-49BB-81A0-98AFC7041599&amp;u_mid=liyadong&amp;u_sd=3F8D6671-D242-4C9A-B69E-616F15FC209D&amp;c_time=1512997145001&amp;l=zh-CN&amp;b_iev=Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A57.0)%20Gecko%2F20100101%20Firefox%2F57.0&amp;b_rst=1366*768<br /><br />点击触发 chargerequest 事件<br /><br />192.168.111.1^A1512997152.777^A192.168.111.123^A/?en=e_crt&amp;oid=123456&amp;on=yabo&amp;cua=300&amp;cut=%24&amp;pt=alipay&amp;ver=1&amp;pl=website&amp;sdk=js&amp;u_ud=11DD76A0-F198-49BB-81A0-98AFC7041599&amp;u_mid=liyadong&amp;u_sd=3F8D6671-D242-4C9A-B69E-616F15FC209D&amp;c_time=1512997231751&amp;l=zh-CN&amp;b_iev=Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A57.0)%20Gecko%2F20100101%20Firefox%2F57.0&amp;b_rst=1366*768<br /><br />处理 订事件<br /><br />192.168.111.1^A1512997196.976^A192.168.111.123^A/index.html?ver=11&amp;u_mid=yaboyabo&amp;en=e_cse_cs&amp;oid=123456123456&amp;sdk=javajava&amp;pl=java_serverjava_server<br /><br /><br /><br /><br /><a name="h2-12"></a><h2>2  prom.xml </h2><br /><br /><span style="color:#e8bf6a;">&lt;?</span><span style="color:#bababa;">xml version</span><span style="color:#6a8759;">="1.0" </span><span style="color:#bababa;">encoding</span><span style="color:#6a8759;">="UTF-8"</span><span style="color:#e8bf6a;">?&gt;<br />&lt;project </span><span style="color:#bababa;">xmlns</span><span style="color:#6a8759;">="http://maven.apache.org/POM/4.0.0"<br />         </span><span style="color:#bababa;">xmlns:</span><span style="color:#9876aa;">xsi</span><span style="color:#6a8759;">="http://www.w3.org/2001/XMLSchema-instance"<br />         </span><span style="color:#9876aa;">xsi</span><span style="color:#bababa;">:schemaLocation</span><span style="color:#6a8759;">="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span><span style="color:#e8bf6a;">&gt;<br />    &lt;modelVersion&gt;</span>4.0.0<span style="color:#e8bf6a;">&lt;/modelVersion&gt;<br /><br />    &lt;groupId&gt;</span>Transform<span style="color:#e8bf6a;">&lt;/groupId&gt;<br />    &lt;artifactId&gt;</span>Transform<span style="color:#e8bf6a;">&lt;/artifactId&gt;<br />    &lt;version&gt;</span>1.0-SNAPSHOT<span style="color:#e8bf6a;">&lt;/version&gt;<br /><br />    &lt;build&gt;<br />        &lt;plugins&gt;<br />            &lt;plugin&gt;<br />                &lt;groupId&gt;</span>org.apache.maven.plugins<span style="color:#e8bf6a;">&lt;/groupId&gt;<br />                &lt;artifactId&gt;</span>maven-compiler-plugin<span style="color:#e8bf6a;">&lt;/artifactId&gt;<br />                &lt;configuration&gt;<br />                    &lt;source&gt;</span>1.8<span style="color:#e8bf6a;">&lt;/source&gt;<br />                    &lt;target&gt;</span>1.8<span style="color:#e8bf6a;">&lt;/target&gt;<br />                &lt;/configuration&gt;<br />            &lt;/plugin&gt;<br />        &lt;/plugins&gt;<br />    &lt;/build&gt;<br /><br /><br />    &lt;dependencies&gt;<br /><br />    &lt;dependency&gt;<br />        &lt;groupId&gt;</span>org.apache.hadoop<span style="color:#e8bf6a;">&lt;/groupId&gt;<br />        &lt;artifactId&gt;</span>hadoop-common<span style="color:#e8bf6a;">&lt;/artifactId&gt;<br />        &lt;version&gt;</span>2.5.0<span style="color:#e8bf6a;">&lt;/version&gt;<br />    &lt;/dependency&gt;<br />    </span><span style="color:#808080;">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-client<br /> --&gt;<br />    </span><span style="color:#e8bf6a;">&lt;dependency&gt;<br />        &lt;groupId&gt;</span>org.apache.hadoop<span style="color:#e8bf6a;">&lt;/groupId&gt;<br />        &lt;artifactId&gt;</span>hadoop-client<span style="color:#e8bf6a;">&lt;/artifactId&gt;<br />        &lt;version&gt;</span>2.5.0<span style="color:#e8bf6a;">&lt;/version&gt;<br />    &lt;/dependency&gt;<br />    </span><span style="color:#808080;">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-hdfs<br /> --&gt;<br />    </span><span style="color:#e8bf6a;">&lt;dependency&gt;<br />        &lt;groupId&gt;</span>org.apache.hadoop<span style="color:#e8bf6a;">&lt;/groupId&gt;<br />        &lt;artifactId&gt;</span>hadoop-hdfs<span style="color:#e8bf6a;">&lt;/artifactId&gt;<br />        &lt;version&gt;</span>2.5.0<span style="color:#e8bf6a;">&lt;/version&gt;<br />    &lt;/dependency&gt;<br /><br />    </span><span style="color:#808080;">&lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase-client --&gt;<br /><br />    </span><span style="color:#e8bf6a;">&lt;dependency&gt;<br />        &lt;groupId&gt;</span>org.apache.hbase<span style="color:#e8bf6a;">&lt;/groupId&gt;<br />        &lt;artifactId&gt;</span>hbase-client<span style="color:#e8bf6a;">&lt;/artifactId&gt;<br />        &lt;version&gt;</span>0.98.6-hadoop2<span style="color:#e8bf6a;">&lt;/version&gt;<br />    &lt;/dependency&gt;<br /><br /><br />    </span><span style="color:#808080;">&lt;!-- https://mvnrepository.com/artifact/log4j/log4j --&gt;<br />    </span><span style="color:#e8bf6a;">&lt;dependency&gt;<br />        &lt;groupId&gt;</span>log4j<span style="color:#e8bf6a;">&lt;/groupId&gt;<br />        &lt;artifactId&gt;</span>log4j<span style="color:#e8bf6a;">&lt;/artifactId&gt;<br />        &lt;version&gt;</span>1.2.17<span style="color:#e8bf6a;">&lt;/version&gt;<br />    &lt;/dependency&gt;<br /><br />        </span><span style="color:#808080;">&lt;!-- https://mvnrepository.com/artifact/cz.mallat.uasparser/uasparser --&gt;<br />    </span><span style="color:#e8bf6a;">&lt;dependency&gt;<br />        &lt;groupId&gt;</span>cz.mallat.uasparser<span style="color:#e8bf6a;">&lt;/groupId&gt;<br />        &lt;artifactId&gt;</span>uasparser<span style="color:#e8bf6a;">&lt;/artifactId&gt;<br />        &lt;version&gt;</span>0.6.2<span style="color:#e8bf6a;">&lt;/version&gt;<br />    &lt;/dependency&gt;<br /><br />    &lt;/dependencies&gt;<br /><br />&lt;/project&gt;</span><br /><br />~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br /><br /><a name="h1-4"></a><h1>3 项目简单记录</h1><br /><br />flume 采集nginx的日志到  logs/12/12 下面 的日志文件	存到hdfs文件系统<br />/gpTransform/month=12/day=12，用于之后的映射hive 表 ，/hive/logs/month=12/day=12<br /><br />jar 包 Tohdfs.jar  存到hdfs上面（/gpTransform/month=12/day=12）<br />yarn jar /home/Myinputdata/HadoopTest/Tohdfs.jar edu.qianfeng.etl.mr.tohdfs.ParserLogDataToHdfsRunner -d 2017-12-12<br /><br /><br /><a name="h2-13"></a><h2>3.1 项目中的错误：</h2><br /><br />core 代码离开 1 :<br />    吧core-site.xml  ，则吧yarn 下面的配置注释了<br />    <br />加载不到主类：<br />    看路径是否写正确：<br /><br /><br />~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br /><br /><a name="h1-5"></a><h1>4  项目中的问题</h1><br /><br /><a name="h1-6"></a><h1>•4.0  ParserLogDataRunner 中的问题</h1><br /><a name="h2-14"></a><h2>    4.1  这个ConcurrentHashMap 有什么好处吗？</h2><br /><img src="images\90-7.png" alt="images\90-7.png" /><br /><br /><a name="h2-15"></a><h2>4.2 clean up</h2><br /><br /><img src="images\90-8.png" alt="images\90-8.png" /><br /><br /><a name="h2-16"></a><h2>4.3 crc32  是干嘛的</h2><br /><br /><img src="images\90-9.png" alt="images\90-9.png" /><br /><img src="images\90-10.png" alt="images\90-10.png" /><br /><br /><br /><a name="h2-17"></a><h2>4.4 赋值了一个date</h2>怎么说？<br /><br /><img src="images\90-11.png" alt="images\90-11.png" /><br /><img src="images\90-12.png" alt="images\90-12.png" /><br /><br /><a name="h2-18"></a><h2>4.5 提交任务</h2><br /><img src="images\90-13.png" alt="images\90-13.png" /><br /><br /><a name="h1-7"></a><h1>4.6 ParserLogDataMapperToHdfs 种问题</h1><br /><br /><img src="images\90-14.png" alt="images\90-14.png" /><br /><br />true啥意思<br /><br /><br /><a name="h1-8"></a><h1>2017/12/22 - 11:01</h1><br /><br /><br />hue ：相当于navicat for mysql 只不过是用浏览器做得<br />oozie:<br />windows 安装request <br /><br /><br /><a name="h2-19"></a><h2>PM</h2><br />python  windows 安装 request  <br /><br />pip  install requests <br /><br /><img src="images\90-15.png" alt="images\90-15.png" /><br /><br />这里是获取的请求header<br />user agent 反爬虫技术<br /><br /><img src="images\90-16.png" alt="images\90-16.png" /><br /><br /><br /><br /><br /><a name="h1-9"></a><h1>N other</h1><br /></div></div>
</body></html>