<!doctype html><html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <title>worldCount准备</title>
  <meta name="generator" content="CherryTree">
  <link rel="stylesheet" href="styles.css" type="text/css" />
</head>
<body><div class="main"><div class="tree">
<p><strong>Index</strong></p>
<p><a href="学习记录.html">学习记录</a></p>

<ol>
<li><a href="学习记录--Needto_Study.html">Needto Study</a></li>
<ol>
<li><a href="学习记录--Needto_Study--NeedStudy_01.html">NeedStudy_01</a></li>
</ol>
<li><a href="学习记录--Sqoop.html">Sqoop</a></li>
<ol>
<li><a href="学习记录--Sqoop--Sqoop_01.html">Sqoop_01</a></li>
<ol>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop介紹.html">Sqoop介紹</a></li>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop命令.html">Sqoop命令</a></li>
<ol>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop命令--Sqoop常用命令.html">Sqoop常用命令</a></li>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop命令--Sqoop测试命令.html">Sqoop测试命令</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--Hadoop.html">Hadoop</a></li>
<ol>
<li><a href="学习记录--Hadoop--Hadoop_介绍.html">Hadoop 介绍</a></li>
<li><a href="学习记录--Hadoop--Hadoop环境搭建.html">Hadoop环境搭建</a></li>
</ol>
<li><a href="学习记录--Linux.html">Linux</a></li>
<ol>
<li><a href="学习记录--Linux--linux_零散命令.html">linux 零散命令</a></li>
</ol>
<li><a href="学习记录--Spark.html">Spark</a></li>
<ol>
<li><a href="学习记录--Spark--Spark_介绍.html">Spark 介绍</a></li>
<li><a href="学习记录--Spark--Spark_搭建.html">Spark 搭建</a></li>
<li><a href="学习记录--Spark--Spark_RDD.html">Spark RDD </a></li>
<li><a href="学习记录--Spark--SparkSQl.html">SparkSQl</a></li>
<li><a href="学习记录--Spark--Spark_other.html">Spark other</a></li>
<ol>
<li><a href="学习记录--Spark--Spark_other--Spark_累加器.html">Spark 累加器</a></li>
</ol>
<li><a href="学习记录--Spark--Spark_每日一记.html">Spark 每日一记</a></li>
</ol>
<li><a href="学习记录--Flume.html">Flume</a></li>
<ol>
<li><a href="学习记录--Flume--Flume_介绍、架构.html">Flume 介绍、架构</a></li>
<li><a href="学习记录--Flume--Flume使用.html">Flume使用</a></li>
<ol>
<li><a href="学习记录--Flume--Flume使用--Flume_1701笔记.html">Flume 1701笔记</a></li>
</ol>
</ol>
<li><a href="学习记录--Kafka.html">Kafka</a></li>
<ol>
<li><a href="学习记录--Kafka--Kafka介绍、运行机制.html">Kafka介绍、运行机制</a></li>
</ol>
<li><a href="学习记录--Hive.html">Hive</a></li>
<ol>
<li><a href="学习记录--Hive--Hive_介绍架构.html">Hive 介绍架构</a></li>
<li><a href="学习记录--Hive--Hive_QL_语句.html">Hive QL 语句</a></li>
<li><a href="学习记录--Hive--Hive_UDF.html">Hive UDF</a></li>
<li><a href="学习记录--Hive--Hive东哥笔记.html">Hive东哥笔记</a></li>
<li><a href="学习记录--Hive--hive_装在数据的几种方式.html">hive 装在数据的几种方式</a></li>
<ol>
<li><a href="学习记录--Hive--hive_装在数据的几种方式--01.html">01</a></li>
</ol>
<li><a href="学习记录--Hive--hive的几种join.html">hive的几种join</a></li>
<ol>
<li><a href="学习记录--Hive--hive的几种join--01.html">01</a></li>
</ol>
</ol>
<li><a href="学习记录--Hbase.html">Hbase </a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记.html">Hbase 命令笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--东哥笔记.html">东哥笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--东哥笔记--hbase笔记总结.html">hbase笔记总结</a></li>
</ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_命令笔记.html">Hbase 命令笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_命令笔记--Hbase命令笔记_01.html">Hbase命令笔记_01</a></li>
</ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_API笔记.html">Hbase API笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_API笔记--Hbase_API笔记.html">Hbase API笔记</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--ELK.html">ELK</a></li>
<ol>
<li><a href="学习记录--ELK--ELK总结.html">ELK总结</a></li>
<li><a href="学习记录--ELK--ELK_博客.html">ELK 博客</a></li>
</ol>
<li><a href="学习记录--ETL.html">ETL</a></li>
<ol>
<li><a href="学习记录--ETL--ETL总结.html">ETL总结</a></li>
<li><a href="学习记录--ETL--ETL_博客.html">ETL 博客</a></li>
</ol>
<li><a href="学习记录--服务器云计算.html">服务器云计算</a></li>
<ol>
<li><a href="学习记录--服务器云计算--简单总结.html">简单总结</a></li>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置.html">linux 添加ss 的配置</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--我的.html">我的</a></li>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令.html">服务器阶段的命令</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--下载安装命令.html">下载安装命令</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--下载安装命令--wget.html">wget</a></li>
</ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--其他配置.html">其他配置</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--其他配置--配置命令.html">配置命令</a></li>
</ol>
</ol>
</ol>
</ol>
<li><a href="学习记录--面试方面.html">面试方面</a></li>
<ol>
<li><a href="学习记录--面试方面--代码准备.html">代码准备</a></li>
<ol>
<li><a href="学习记录--面试方面--代码准备--代码准备_01.html">代码准备_01</a></li>
<ol>
<li><a href="学习记录--面试方面--代码准备--代码准备_01--worldCount准备.html">worldCount准备</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--每天记录.html">每天记录</a></li>
<ol>
<li><a href="学习记录--每天记录--今日整理待整理.html">今日整理待整理</a></li>
</ol>
<li><a href="学习记录--cdh(东哥hadoop项目).html">cdh(东哥hadoop项目)</a></li>
<ol>
<li><a href="学习记录--cdh(东哥hadoop项目)--cdh配置.html">cdh配置</a></li>
<ol>
<li><a href="学习记录--cdh(东哥hadoop项目)--cdh配置--cdh安装.html">cdh安装 </a></li>
<li><a href="学习记录--cdh(东哥hadoop项目)--cdh配置--cdh安装集群模式.html">cdh安装集群模式</a></li>
</ol>
<li><a href="学习记录--cdh(东哥hadoop项目)--Hadoop项目笔记.html">Hadoop项目笔记</a></li>
<li><a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html">项目公共日志</a></li>
</ol>
<li><a href="学习记录--Hadoop、spark等进程.html">Hadoop、spark等进程</a></li>
<ol>
<li><a href="学习记录--Hadoop、spark等进程--Hadoop-spakr-zookeeper-等.html">Hadoop/spakr/zookeeper/等</a></li>
</ol>
<li><a href="学习记录--其他技术.html">其他技术</a></li>
<ol>
<li><a href="学习记录--其他技术--内存与磁盘问题.html">内存与磁盘问题</a></li>
<li><a href="学习记录--其他技术--flink.html">flink</a></li>
<li><a href="学习记录--其他技术--VPN搭建.html">VPN搭建</a></li>
<ol>
<li><a href="学习记录--其他技术--VPN搭建--服务器地址pas.html">服务器地址pas</a></li>
<ol>
<li><a href="学习记录--其他技术--VPN搭建--服务器地址pas--free_IP.html">free IP</a></li>
</ol>
</ol>
<li><a href="学习记录--其他技术--人工智能.html">人工智能</a></li>
<ol>
<li><a href="学习记录--其他技术--人工智能--人工智能书单.html">人工智能书单</a></li>
<ol>
<li><a href="学习记录--其他技术--人工智能--人工智能书单--人工智能书单_01.html">人工智能书单_01</a></li>
</ol>
<li><a href="学习记录--其他技术--人工智能--人工智能算法.html">人工智能算法</a></li>
<ol>
<li><a href="学习记录--其他技术--人工智能--人工智能算法--人工智能算法——01.html">人工智能算法——01</a></li>
</ol>
</ol>
<li><a href="学习记录--其他技术--下载地址.html">下载地址</a></li>
<ol>
<li><a href="学习记录--其他技术--下载地址--创作社区.html">创作社区</a></li>
<li><a href="学习记录--其他技术--下载地址--it创作社区.html">it创作社区</a></li>
<li><a href="学习记录--其他技术--下载地址--源码解读.html">源码解读</a></li>
<li><a href="学习记录--其他技术--下载地址--复习语句总结.html">复习语句总结</a></li>
<ol>
<li><a href="学习记录--其他技术--下载地址--复习语句总结--复习语句总结.html">复习语句总结</a></li>
</ol>
</ol>
<li><a href="学习记录--其他技术--负载均衡.html">负载均衡</a></li>
<ol>
<li><a href="学习记录--其他技术--负载均衡--负载均衡_01.html">负载均衡_01</a></li>
</ol>
</ol>
<li><a href="学习记录--Phthon.html">Phthon</a></li>
<ol>
<li><a href="学习记录--Phthon--python_使用spark.html">python 使用spark</a></li>
</ol>
<li><a href="学习记录--数据结构.html">数据结构</a></li>
<ol>
<li><a href="学习记录--数据结构--数据结构1.html">数据结构1</a></li>
<ol>
<li><a href="学习记录--数据结构--数据结构1--Hash_问题.html">Hash 问题</a></li>
<li><a href="学习记录--数据结构--数据结构1--数据结构中的树.html">数据结构中的树</a></li>
<ol>
<li><a href="学习记录--数据结构--数据结构1--数据结构中的树--数据结构树是怎么遍历的.html">数据结构树是怎么遍历的</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--通信协议.html">通信协议</a></li>
<li><a href="学习记录--开发工具记录.html">开发工具记录</a></li>
<ol>
<li><a href="学习记录--开发工具记录--idea_的一些记录.html">idea 的一些记录</a></li>
<li><a href="学习记录--开发工具记录--博客地址.html">博客地址</a></li>
</ol>
<li><a href="学习记录--数据库.html">数据库</a></li>
<ol>
<li><a href="学习记录--数据库--mysql.html">mysql</a></li>
</ol></ol></div>
<div class="page"><h1><b><u>worldCount准备</u></b></h1><br />• <a href="学习记录--面试方面--代码准备--代码准备_01--worldCount准备.html#h1-1">1 Awk 实现worldcount</a><br />• <a href="学习记录--面试方面--代码准备--代码准备_01--worldCount准备.html#h1-2">2 java API实现world Count </a><br />• <a href="学习记录--面试方面--代码准备--代码准备_01--worldCount准备.html#h1-3">3 Scala实现World Count</a><br /><br /><br /><br /><a name="h1-1"></a><h1>1 Awk 实现worldcount</h1><br /><br /><br />WordCount:<br /><br />awk 'BEGIN{FS=",";OFS="\t"} {for( i = 1;i&lt;=NF; i++) Number[$i]++} END{for(i in Number) print i,Number[i]}' /home/inputdata/person<br />mahui is very handsome<br />yes yes yes <br /><br /><br /><br />1.	什么是awk<br />awk是Unix/Linux提供的样式扫描与处理工具，<br />非常擅长处理结构化数据和生成表单。<br />由于awk具备各种脚本语言的特点，<br />所以也可以把它看做一种脚本语言。<br /><br />2.awk中变量：<br />自定义变量：<br />FS：输入数据的字段分割符，默认是空格或\t<br />RS：输入数据的记录分隔符，默认是换行符<br />OFS：输输出数据的字段分割符，<br />ORS：输出数据的记录分隔符<br />......<br /><br />系统变量：<br />$0:表示当前所读入的一行数据<br />$1:第1个字段的数据<br />$2:第2个字段的数据<br />NF：当前记录的字段个数，<br />NR：当前记录编号(行号)。<br />FILENAMEawk： 正在处理的数据文件文件名<br /><br /><br /><br />3.awk程序设计模型<br />awk程序由三部分组成<br /><br />初始化（处理输入前做的准备,放在BEGIN块中），BEGIN{}<br />数据处理（处理输入数据,指令被写成一系列模式/动作过程），PATTERN1{Action} PATTERN1{Action}<br />收尾处理（处理输入完成后要进行的处理，放到END块中）。<br />其中，在“数据处理”过程中，<br /><br /><br /><br /><br /><br /><br />4.awk的工作流 程 :<br />执行 awk时, 它会反复进行下列四步骤.<br />1. 自动从指定的数据文件中读取一个数据行.<br />2. 自动更新(Update)相关的内建变量之值. 如 : NF, NR, $0...<br />3. 依次执行程序中 所有 的 Pattern {Actions } 指令.<br />4. 当执行完程序中所有 Pattern { Actions } 时, 若数据文件中还有未读取的数据, 则反复执行步骤 1 到步骤 4.<br />awk会自动重复进行上述 4 个步骤, 使用者不须于程序中编写这个循环 (Loop). <br /><br /><br /><br /><br /><br />5.awk 中数组<br />1：可以用数值作数组索引(下标)<br /><br />Tarray[1]="cheng mo"<br />Tarray[2]="800927"<br /><br />2：可以用字符串作数组索引(下标)<br /><br />Tarray["first"]="cheng "<br />Tarray["last"]="mo"<br />Tarray["birth"]="800927"<br /><br />数组元素用 0 或空串来初始化，这根据上下文而定<br /><br />当数组的初始值是""时，也可进行算术运算(这是可以看做数字0)<br /><br />数组的两种输出方式：<br />和Java,C语言不同的是，数组的下标是从1开始<br />1.for(i = 1 ; i &lt; args.length; i++){<br />	print args[i]<br />}<br /><br />把下标赋给变量<br />2.for(index in args){<br />	print args[index]<br />}<br /><br /><br /><br /><br /><br /><br /><br /><br /><br />~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br /><br /><a name="h1-2"></a><h1>2 java API实现world Count </h1><br /><br /><span style="color:#cc7832;">import </span>org.apache.spark.SparkConf<span style="color:#cc7832;">;<br />import </span>org.apache.spark.api.java.JavaPairRDD<span style="color:#cc7832;">;<br />import </span>org.apache.spark.api.java.JavaRDD<span style="color:#cc7832;">;<br />import </span>org.apache.spark.api.java.JavaSparkContext<span style="color:#cc7832;">;<br />import </span>org.apache.spark.api.java.function.FlatMapFunction<span style="color:#cc7832;">;<br />import </span>org.apache.spark.api.java.function.Function2<span style="color:#cc7832;">;<br />import </span>org.apache.spark.api.java.function.PairFunction<span style="color:#cc7832;">;<br />import </span>scala.Tuple2<span style="color:#cc7832;">;<br /><br />import </span>java.util.Arrays<span style="color:#cc7832;">;<br /><br />public class </span>javaWC {<br />    <span style="color:#cc7832;">public static void </span><span style="color:#ffc66d;">main</span>(String[] args) {<br />        <span style="color:#808080;">//创建一个配置信息类<br />        </span><span style="color:#cc7832;">final </span>SparkConf conf = <span style="color:#cc7832;">new </span>SparkConf().setAppName(<span style="color:#6a8759;">"JavaWC"</span>).setMaster(<span style="color:#6a8759;">"local[2]"</span>)<span style="color:#cc7832;">;<br /><br />        </span><span style="color:#808080;">//创建上下文对象<br />        </span><span style="color:#cc7832;">final </span>JavaSparkContext jsc =<span style="color:#cc7832;">new </span>JavaSparkContext(conf)<span style="color:#cc7832;">;<br /><br />        </span><span style="color:#808080;">//捕获数据<br />        </span><span style="color:#cc7832;">final </span>JavaRDD&lt;String&gt; lines = jsc.textFile(args[<span style="color:#6897bb;">0</span>])<span style="color:#cc7832;">;<br /><br />        </span><span style="color:#808080;">//切分数据<br />        </span><span style="color:#cc7832;">final </span>JavaRDD&lt;String&gt; words = lines.flatMap(<span style="color:#cc7832;">new </span>FlatMapFunction&lt;String<span style="color:#cc7832;">, </span>String&gt;() {<br /><br />            <span style="color:#bbb529;">@Override<br />            </span><span style="color:#cc7832;">public </span>Iterable&lt;String&gt; <span style="color:#ffc66d;">call</span>(String s) <span style="color:#cc7832;">throws </span>Exception {<br />                <span style="color:#cc7832;">return </span>Arrays.<em>asList</em>(s.split(<span style="color:#6a8759;">" "</span>))<span style="color:#cc7832;">;<br />            </span>}<br />        })<span style="color:#cc7832;">;<br /><br />        </span><span style="color:#808080;">// 把单词生成javaPairRDD（类似于元祖）<br />        </span><span style="color:#cc7832;">final </span>JavaPairRDD&lt;String<span style="color:#cc7832;">, </span>Integer&gt; pairRDD = words.mapToPair(<span style="color:#cc7832;">new </span>PairFunction&lt;String<span style="color:#cc7832;">, </span>String<span style="color:#cc7832;">, </span>Integer&gt;() {<br /><br />            <span style="color:#bbb529;">@Override<br />            </span><span style="color:#cc7832;">public </span>Tuple2&lt;String<span style="color:#cc7832;">, </span>Integer&gt; <span style="color:#ffc66d;">call</span>(String s) <span style="color:#cc7832;">throws </span>Exception {<br />                <span style="color:#cc7832;">return new </span>Tuple2&lt;String<span style="color:#cc7832;">, </span>Integer&gt;(s<span style="color:#cc7832;">, </span><span style="color:#6897bb;">1</span>)<span style="color:#cc7832;">;<br />            </span>}<br />        })<span style="color:#cc7832;">;<br />        </span><span style="color:#808080;">//聚合：<br />        </span><span style="color:#cc7832;">final </span>JavaPairRDD&lt;String<span style="color:#cc7832;">, </span>Integer&gt; reduced = pairRDD.reduceByKey(<span style="color:#cc7832;">new </span>Function2&lt;Integer<span style="color:#cc7832;">, </span>Integer<span style="color:#cc7832;">, </span>Integer&gt;() {<br />            <span style="color:#bbb529;">@Override<br />            </span><span style="color:#cc7832;">public </span>Integer <span style="color:#ffc66d;">call</span>(Integer v1<span style="color:#cc7832;">, </span>Integer v2) <span style="color:#cc7832;">throws </span>Exception {<br />                <span style="color:#cc7832;">return </span>v1+v2<span style="color:#cc7832;">;<br />            </span>}<br />        })<span style="color:#cc7832;">;<br />        </span><span style="color:#808080;">//java 语言没有提供sort by 方法，如果需要把pairRDD里的数据<br />        //两个值互换，然后调用sortByKey来进行排序,排序后<br />        //reduced.sortByKey();<br /><br />        </span><span style="color:#cc7832;">final </span>JavaPairRDD&lt;Integer<span style="color:#cc7832;">, </span>String&gt; swaped = reduced.mapToPair(<span style="color:#cc7832;">new </span>PairFunction&lt;Tuple2&lt;String<span style="color:#cc7832;">, </span>Integer&gt;<span style="color:#cc7832;">, </span>Integer<span style="color:#cc7832;">, </span>String&gt;() {<br />            <span style="color:#bbb529;">@Override<br />            </span><span style="color:#cc7832;">public </span>Tuple2&lt;Integer<span style="color:#cc7832;">, </span>String&gt; <span style="color:#ffc66d;">call</span>(Tuple2&lt;String<span style="color:#cc7832;">, </span>Integer&gt; tup) <span style="color:#cc7832;">throws </span>Exception {<br />                <span style="color:#cc7832;">return </span>tup.swap()<span style="color:#cc7832;">;<br />            </span>}<br />        })<span style="color:#cc7832;">;<br />        </span><span style="color:#808080;">//降序排序<br />        </span><span style="color:#cc7832;">final </span>JavaPairRDD&lt;Integer<span style="color:#cc7832;">, </span>String&gt; sorted = swaped.sortByKey(<span style="color:#cc7832;">false</span>)<span style="color:#cc7832;">;<br /><br />        final </span>JavaPairRDD&lt;String<span style="color:#cc7832;">, </span>Integer&gt; res = sorted.mapToPair(<span style="color:#cc7832;">new </span>PairFunction&lt;Tuple2&lt;Integer<span style="color:#cc7832;">, </span>String&gt;<span style="color:#cc7832;">, </span>String<span style="color:#cc7832;">, </span>Integer&gt;() {<br />            <span style="color:#bbb529;">@Override<br />            </span><span style="color:#cc7832;">public </span>Tuple2&lt;String<span style="color:#cc7832;">, </span>Integer&gt; <span style="color:#ffc66d;">call</span>(Tuple2&lt;Integer<span style="color:#cc7832;">, </span>String&gt; tup) <span style="color:#cc7832;">throws </span>Exception {<br />                <span style="color:#cc7832;">return </span>tup.swap()<span style="color:#cc7832;">;<br />            </span>}<br />        })<span style="color:#cc7832;">;<br />        </span>System.<em><span style="color:#9876aa;">out</span></em><em>.println(res.collect())</em><em><span style="color:#cc7832;">;<br />        </span></em><em>jsc.stop()</em><em><span style="color:#cc7832;">;<br />    </span></em><em>}<br />}</em><br /><br />~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br /><br /><br /><br /><br /><a name="h1-3"></a><h1>3 Scala实现World Count</h1><br /><br /><strong><span style="color:#cc7832;">import </span></strong><strong>org.apache.spark.rdd.RDD<br /></strong><strong><span style="color:#cc7832;">import </span></strong><strong>org.apache.spark.{SparkConf</strong><strong><span style="color:#cc7832;">, </span></strong><strong>SparkContext}<br /><br /></strong><strong><span style="color:#cc7832;">object </span></strong><strong>SparkWc {<br />  </strong><strong><span style="color:#cc7832;">def </span></strong><strong><span style="color:#ffc66d;">main</span></strong><strong>(args: Array[</strong><strong><span style="color:#4e807d;">String</span></strong><strong>]): </strong><strong><span style="color:#cc7832;">Unit </span></strong><strong>= {<br /><br />    </strong><strong><span style="color:#808080;">//创建配置信息类，并设置应用程序名称（setAppName)<br />    //local[2] /本地启用两个线程模拟集群运行任务<br />    //local[*] 本地有多少个空闲线程就起用多少个线程来运行任务<br />    //集群上的时候吧后面的删了<br />  //  val conf: SparkConf = new SparkConf().setAppName("SparkWc").setMaster("local[*]")<br />   </span></strong><strong><span style="color:#cc7832;">val </span></strong><strong>conf: SparkConf = </strong><strong><span style="color:#cc7832;">new </span></strong><strong>SparkConf().setAppName(</strong><strong><span style="color:#6a8759;">"SparkWc-SparkOnYarn"</span></strong><strong>)<br /><br />    </strong><strong><span style="color:#808080;">//创建Spark的上下文对象，也是提交任务到集群的入口类<br />    </span></strong><strong><span style="color:#cc7832;">val </span></strong><strong>sc: SparkContext = </strong><strong><span style="color:#cc7832;">new </span></strong><strong>SparkContext(conf)<br /><br />    </strong><strong><span style="color:#808080;">//读取数据<br />    </span></strong><strong><span style="color:#cc7832;">val </span></strong><strong>lines: RDD[</strong><strong><span style="color:#4e807d;">String</span></strong><strong>] = sc.textFile(args(</strong><strong><span style="color:#6897bb;">0</span></strong><strong>))<br />    </strong><strong><span style="color:#808080;">//处理数据<br />    </span></strong><strong><span style="color:#cc7832;">val </span></strong><strong>words: RDD[</strong><strong><span style="color:#4e807d;">String</span></strong><strong>] = lines.flatMap(_.split(</strong><strong><span style="color:#6a8759;">" "</span></strong><strong>))<br />    </strong><strong><span style="color:#cc7832;">val </span></strong><strong>tup: RDD[(</strong><strong><span style="color:#4e807d;">String</span></strong><strong><span style="color:#cc7832;">, Int</span></strong><strong>)] = words.map((_</strong><strong><span style="color:#cc7832;">,</span></strong><strong><span style="color:#6897bb;">1</span></strong><strong>))<br />    </strong><strong><span style="color:#cc7832;">val </span></strong><strong>reduced: RDD[(</strong><strong><span style="color:#4e807d;">String</span></strong><strong><span style="color:#cc7832;">, Int</span></strong><strong>)] = tup.reduceByKey(_+_)<br />    </strong><strong><span style="color:#cc7832;">val </span></strong><strong>res: RDD[(</strong><strong><span style="color:#4e807d;">String</span></strong><strong><span style="color:#cc7832;">, Int</span></strong><strong>)] = reduced.sortBy(_._2</strong><strong><span style="color:#cc7832;">,false</span></strong><strong>)<br />   </strong><strong><span style="color:#808080;">//集群上的时候，要保存到一个地址<br />    //res.saveAsTextFile(args(1))<br />    </span></strong><strong>res.saveAsTextFile(</strong><strong><span style="color:#6a8759;">"hdfs://hadoop:9000/Today/out/PM/SparkOnYarn"</span></strong><strong>)<br />   </strong><strong><span style="color:#808080;">// println(res.collect.toBuffer)<br />  </span></strong><strong>}<br />}<br /></strong><br /><br />~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~<br /><br /><br />N :Other </div></div>
</body></html>