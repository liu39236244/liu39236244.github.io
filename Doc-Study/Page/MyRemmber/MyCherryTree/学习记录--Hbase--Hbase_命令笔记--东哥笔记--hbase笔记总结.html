<!doctype html><html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <title>hbase笔记总结</title>
  <meta name="generator" content="CherryTree">
  <link rel="stylesheet" href="styles.css" type="text/css" />
</head>
<body><div class="main"><div class="tree">
<p><strong>Index</strong></p>
<p><a href="学习记录.html">学习记录</a></p>

<ol>
<li><a href="学习记录--Needto_Study.html">Needto Study</a></li>
<ol>
<li><a href="学习记录--Needto_Study--NeedStudy_01.html">NeedStudy_01</a></li>
</ol>
<li><a href="学习记录--Sqoop.html">Sqoop</a></li>
<ol>
<li><a href="学习记录--Sqoop--Sqoop_01.html">Sqoop_01</a></li>
<ol>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop介紹.html">Sqoop介紹</a></li>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop命令.html">Sqoop命令</a></li>
<ol>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop命令--Sqoop常用命令.html">Sqoop常用命令</a></li>
<li><a href="学习记录--Sqoop--Sqoop_01--Sqoop命令--Sqoop测试命令.html">Sqoop测试命令</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--Hadoop.html">Hadoop</a></li>
<ol>
<li><a href="学习记录--Hadoop--Hadoop_介绍.html">Hadoop 介绍</a></li>
<li><a href="学习记录--Hadoop--Hadoop环境搭建.html">Hadoop环境搭建</a></li>
</ol>
<li><a href="学习记录--Linux.html">Linux</a></li>
<ol>
<li><a href="学习记录--Linux--linux_零散命令.html">linux 零散命令</a></li>
</ol>
<li><a href="学习记录--Spark.html">Spark</a></li>
<ol>
<li><a href="学习记录--Spark--Spark_介绍.html">Spark 介绍</a></li>
<li><a href="学习记录--Spark--Spark_搭建.html">Spark 搭建</a></li>
<li><a href="学习记录--Spark--Spark_RDD.html">Spark RDD </a></li>
<li><a href="学习记录--Spark--SparkSQl.html">SparkSQl</a></li>
<li><a href="学习记录--Spark--Spark_other.html">Spark other</a></li>
<ol>
<li><a href="学习记录--Spark--Spark_other--Spark_累加器.html">Spark 累加器</a></li>
</ol>
<li><a href="学习记录--Spark--Spark_每日一记.html">Spark 每日一记</a></li>
</ol>
<li><a href="学习记录--Flume.html">Flume</a></li>
<ol>
<li><a href="学习记录--Flume--Flume_介绍、架构.html">Flume 介绍、架构</a></li>
<li><a href="学习记录--Flume--Flume使用.html">Flume使用</a></li>
<ol>
<li><a href="学习记录--Flume--Flume使用--Flume_1701笔记.html">Flume 1701笔记</a></li>
</ol>
</ol>
<li><a href="学习记录--Kafka.html">Kafka</a></li>
<ol>
<li><a href="学习记录--Kafka--Kafka介绍、运行机制.html">Kafka介绍、运行机制</a></li>
</ol>
<li><a href="学习记录--Hive.html">Hive</a></li>
<ol>
<li><a href="学习记录--Hive--Hive_介绍架构.html">Hive 介绍架构</a></li>
<li><a href="学习记录--Hive--Hive_QL_语句.html">Hive QL 语句</a></li>
<li><a href="学习记录--Hive--Hive_UDF.html">Hive UDF</a></li>
<li><a href="学习记录--Hive--Hive东哥笔记.html">Hive东哥笔记</a></li>
<li><a href="学习记录--Hive--hive_装在数据的几种方式.html">hive 装在数据的几种方式</a></li>
<ol>
<li><a href="学习记录--Hive--hive_装在数据的几种方式--01.html">01</a></li>
</ol>
<li><a href="学习记录--Hive--hive的几种join.html">hive的几种join</a></li>
<ol>
<li><a href="学习记录--Hive--hive的几种join--01.html">01</a></li>
</ol>
</ol>
<li><a href="学习记录--Hbase.html">Hbase </a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记.html">Hbase 命令笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--东哥笔记.html">东哥笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--东哥笔记--hbase笔记总结.html">hbase笔记总结</a></li>
</ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_命令笔记.html">Hbase 命令笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_命令笔记--Hbase命令笔记_01.html">Hbase命令笔记_01</a></li>
</ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_API笔记.html">Hbase API笔记</a></li>
<ol>
<li><a href="学习记录--Hbase--Hbase_命令笔记--Hbase_API笔记--Hbase_API笔记.html">Hbase API笔记</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--ELK.html">ELK</a></li>
<ol>
<li><a href="学习记录--ELK--ELK总结.html">ELK总结</a></li>
<li><a href="学习记录--ELK--ELK_博客.html">ELK 博客</a></li>
</ol>
<li><a href="学习记录--ETL.html">ETL</a></li>
<ol>
<li><a href="学习记录--ETL--ETL总结.html">ETL总结</a></li>
<li><a href="学习记录--ETL--ETL_博客.html">ETL 博客</a></li>
</ol>
<li><a href="学习记录--服务器云计算.html">服务器云计算</a></li>
<ol>
<li><a href="学习记录--服务器云计算--简单总结.html">简单总结</a></li>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置.html">linux 添加ss 的配置</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--我的.html">我的</a></li>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令.html">服务器阶段的命令</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--下载安装命令.html">下载安装命令</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--下载安装命令--wget.html">wget</a></li>
</ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--其他配置.html">其他配置</a></li>
<ol>
<li><a href="学习记录--服务器云计算--linux_添加ss_的配置--服务器阶段的命令--其他配置--配置命令.html">配置命令</a></li>
</ol>
</ol>
</ol>
</ol>
<li><a href="学习记录--面试方面.html">面试方面</a></li>
<ol>
<li><a href="学习记录--面试方面--代码准备.html">代码准备</a></li>
<ol>
<li><a href="学习记录--面试方面--代码准备--代码准备_01.html">代码准备_01</a></li>
<ol>
<li><a href="学习记录--面试方面--代码准备--代码准备_01--worldCount准备.html">worldCount准备</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--每天记录.html">每天记录</a></li>
<ol>
<li><a href="学习记录--每天记录--今日整理待整理.html">今日整理待整理</a></li>
</ol>
<li><a href="学习记录--cdh(东哥hadoop项目).html">cdh(东哥hadoop项目)</a></li>
<ol>
<li><a href="学习记录--cdh(东哥hadoop项目)--cdh配置.html">cdh配置</a></li>
<ol>
<li><a href="学习记录--cdh(东哥hadoop项目)--cdh配置--cdh安装.html">cdh安装 </a></li>
<li><a href="学习记录--cdh(东哥hadoop项目)--cdh配置--cdh安装集群模式.html">cdh安装集群模式</a></li>
</ol>
<li><a href="学习记录--cdh(东哥hadoop项目)--Hadoop项目笔记.html">Hadoop项目笔记</a></li>
<li><a href="学习记录--cdh(东哥hadoop项目)--项目公共日志.html">项目公共日志</a></li>
</ol>
<li><a href="学习记录--Hadoop、spark等进程.html">Hadoop、spark等进程</a></li>
<ol>
<li><a href="学习记录--Hadoop、spark等进程--Hadoop-spakr-zookeeper-等.html">Hadoop/spakr/zookeeper/等</a></li>
</ol>
<li><a href="学习记录--其他技术.html">其他技术</a></li>
<ol>
<li><a href="学习记录--其他技术--内存与磁盘问题.html">内存与磁盘问题</a></li>
<li><a href="学习记录--其他技术--flink.html">flink</a></li>
<li><a href="学习记录--其他技术--VPN搭建.html">VPN搭建</a></li>
<ol>
<li><a href="学习记录--其他技术--VPN搭建--服务器地址pas.html">服务器地址pas</a></li>
<ol>
<li><a href="学习记录--其他技术--VPN搭建--服务器地址pas--free_IP.html">free IP</a></li>
</ol>
</ol>
<li><a href="学习记录--其他技术--人工智能.html">人工智能</a></li>
<ol>
<li><a href="学习记录--其他技术--人工智能--人工智能书单.html">人工智能书单</a></li>
<ol>
<li><a href="学习记录--其他技术--人工智能--人工智能书单--人工智能书单_01.html">人工智能书单_01</a></li>
</ol>
<li><a href="学习记录--其他技术--人工智能--人工智能算法.html">人工智能算法</a></li>
<ol>
<li><a href="学习记录--其他技术--人工智能--人工智能算法--人工智能算法——01.html">人工智能算法——01</a></li>
</ol>
</ol>
<li><a href="学习记录--其他技术--下载地址.html">下载地址</a></li>
<ol>
<li><a href="学习记录--其他技术--下载地址--创作社区.html">创作社区</a></li>
<li><a href="学习记录--其他技术--下载地址--it创作社区.html">it创作社区</a></li>
<li><a href="学习记录--其他技术--下载地址--源码解读.html">源码解读</a></li>
<li><a href="学习记录--其他技术--下载地址--复习语句总结.html">复习语句总结</a></li>
<ol>
<li><a href="学习记录--其他技术--下载地址--复习语句总结--复习语句总结.html">复习语句总结</a></li>
</ol>
</ol>
<li><a href="学习记录--其他技术--负载均衡.html">负载均衡</a></li>
<ol>
<li><a href="学习记录--其他技术--负载均衡--负载均衡_01.html">负载均衡_01</a></li>
</ol>
</ol>
<li><a href="学习记录--Phthon.html">Phthon</a></li>
<ol>
<li><a href="学习记录--Phthon--python_使用spark.html">python 使用spark</a></li>
</ol>
<li><a href="学习记录--数据结构.html">数据结构</a></li>
<ol>
<li><a href="学习记录--数据结构--数据结构1.html">数据结构1</a></li>
<ol>
<li><a href="学习记录--数据结构--数据结构1--Hash_问题.html">Hash 问题</a></li>
<li><a href="学习记录--数据结构--数据结构1--数据结构中的树.html">数据结构中的树</a></li>
<ol>
<li><a href="学习记录--数据结构--数据结构1--数据结构中的树--数据结构树是怎么遍历的.html">数据结构树是怎么遍历的</a></li>
</ol>
</ol>
</ol>
<li><a href="学习记录--通信协议.html">通信协议</a></li>
<li><a href="学习记录--开发工具记录.html">开发工具记录</a></li>
<ol>
<li><a href="学习记录--开发工具记录--idea_的一些记录.html">idea 的一些记录</a></li>
<li><a href="学习记录--开发工具记录--博客地址.html">博客地址</a></li>
</ol>
<li><a href="学习记录--数据库.html">数据库</a></li>
<ol>
<li><a href="学习记录--数据库--mysql.html">mysql</a></li>
</ol></ol></div>
<div class="page"><h1><b><u>hbase笔记总结</u></b></h1>RDBMS:mysql 、oracle 、sqlserver 、 db2 、access 等。<br />NO-SQL:hbase 、 mongodb 、 redis 、 memChache等。<br /><br /><br />为什么有hbase？？<br />随着数据量越来越大，传统的关系型数据库已经不能满足要求。hive虽然能满足存储，<br />但是不能满足非结构化的存储和高效查询。<br /><br /><br />hbase是什么？？<br />Apache HBase is the Hadoop database, a distributed, scalable, big data store.<br /><br />Use Apache HBase when you need random, realtime read/write access to your Big Data. <br />This project's goal is the hosting of very large tables -- <br />billions of rows X millions of columns -- atop clusters of commodity hardware. <br />Apache HBase is an open-source, distributed, versioned, non-relational database <br />modeled after Google's Bigtable: A Distributed Storage System for Structured Data by Chang et al. <br />Just as Bigtable leverages the distributed data storage provided by the Google File System, <br />Apache HBase provides Bigtable-like capabilities on top of Hadoop and HDFS.<br /><br />hbase是一个开源、分布式的、多版本的、可扩展的非关系型数据库。<br />适用场景：<br />需要海量非机构化数据进行存储。<br />需要随机近实时读写数据。<br /><br />hbase 和hadoop的关系：<br />hbase基于hadoop：hbase的存储依靠于hdfs<br /><br />hbase架构？？<br />client、zookeeper、hmaster<br />hregionserver、hlog、hregion、stroe、memstore、storefile、hfile<br /><br />client：habse的客户端(linux shell、java操作)<br />zookeeper：<br />监控hmaster的状态，保证有且仅有一个active的hmaster，达到高可用。<br />存储所有hregion的寻址入口。<br />存储hbase的所有表信息。<br /><br />hmaster:(hbase的老大)<br />管理所有的hregionserver。<br />管理hregion的分配(新建hbase表等)<br />负责hregion的重新分配(hregionserver异常、hregion变大时一分为二)<br />负责整个集群的负载。<br />负责client对所有表的操作，读、写。<br /><br />hregionserver：(hbase的小弟)<br />主要负责来自于clint端的所有i/o请求，并和hdfs的交互<br />管理当前几点的所有的hregion<br /><br />Hlog：对hbase的操作进行记录，使用WAL写数据优先写到hlog里面，然后再写到memstore。以防数据丢失可以进行回滚。<br /><br />hregion：表或者表的一部分。<br /><br />store:相当于一个列簇。<br /><br />memstore：内存缓冲区，用于进行批量刷新到hdfs上。<br /><br />HFile ：hbase中的数据以hfile的形式存储到hdfs中。<br /><br />hmaster:hregionser=1:n<br />hregionserver:hregion=1:n<br />hregionserver:hlog=1:1<br />hregion:store=1:n<br />store:memstore=1:1<br />store:storefile=1:n  &lt;???&gt;<br />storefile:hfile=1:n  &lt;???&gt;<br /><br /><br /><br />hbase 关键关键词？？<br />rowkey：行键(和mysql中的主键一样),不允许重复，有顺序。<br />columnfamily:列簇(列的集合)。<br />column:列<br /><br />timestamp:时间戳。(默认显示最新的时间戳)<br />version:版本号 <br />cell: 单元格()。<br /><br /><br />hbase的特点？？<br /><br />模式：无模式<br />数据类型：单一<br />多版本：每个值都可以有多个版本<br />稀疏存储：如果key-value为null时，整个将不会占用空间。<br /><br />habse 安装？？<br />1、Standalone HBase<br />解压并配置环境变量<br />配置./conf/hbase-env.sh<br />配置./conf/hbase-site.xml<br />测试：<br />启动：<br />./bin/start-hbase.sh<br />连接hbase：<br />./bin/hbase shell<br /><br /><br />3、Fully Distributed<br />规划：<br />hadoop01	192.168.216.111	hmaster、zk、hregionser<br />hadoop02	192.168.216.112	hmaster_backup、zk、hregionser<br />hadoop03	192.168.216.113	hmaster_backup、zk、hregionser<br /><br />配置：<br />解压并配置环境变量<br />配置./conf/hbase-env.sh<br />配置./conf/regionservers (小弟文件)<br />配置./conf/backup-masters (指定backup master)<br />配置./conf/hbase-site.xml<br /><br /><br />先启动zk和hadoop的hdfs<br />然后启动hbase<br /><br />注意：<br />habse集群的节点的时间需要同步<br />hmaster：16010<br />hregionserver:16030<br /><br /><br />hbase shell操作？？<br />help "COMMAND"<br />'help "COMMAND_GROUP"'<br /><br /><br /><br />put 'test','rk1','cf1:name','zs','cf1:age','18'<br /><br /><br />hbase没有库的概念，但是有命名空间后者组的概念，namespace(相当于库)<br />hbase默认有两个组：<br />default：<br />hbase：<br /><br />namespace：<br />list_namespace<br />list_namespace_tables<br />create_namespace<br />describe_namespace 'ns2'<br />alter_namespace 'ns2',{NAME=&gt;'ns3'}<br />drop_namespace 'ns2'<br /><br />？？？为namespace授权？？？<br /><br />创建表：<br />create 'ns1:test',{NAME=&gt;'info'},{NAME=&gt;'log'},{NAME=&gt;'time',BLOCKCACHE =&gt; 'false'}<br />#修改表：(有就更新，没有则新增)<br />alter 'ns1:test',{NAME=&gt;'info'},{NAME=&gt;'log'},{NAME=&gt;'time',BLOCKCACHE =&gt; 'false'}<br />删除表列族：<br />alter 'ns1:test',{NAME=&gt;'time',METHOD=&gt;'delete'}<br /><br />插入数据：(不能一次性插入多列)<br />put 'ns1:test','rk1','info:name',"zs"<br />put 'ns1:test','rk1','info:age',"18"<br />put 'ns1:test','rk1','info:sex',"2"<br />put 'ns1:test','rk2','info:name',"ls"<br />put 'ns1:test','rk2','info:age',"19"<br />put 'ns1:test','rk2','info:sex',"1"<br />put 'ns1:test','rk3','info:name',"ws"<br />put 'ns1:test','rk3','info:sex',"1"<br />put 'ns1:test','rk3','info:age',"23"<br />put 'ns1:test','rk4','info:name',"zl2"<br />put 'ns1:test','rk5','info:name',"zhaosi2"<br />put 'ns1:test','rk5','info:age',"5"<br />put 'ns1:test','rk6','info:name',"qq6"<br /><br />更新的数据：<br />put 'ns1:test','rk1','info:age',"100"<br />put 'ns1:test','rk1','info:age',"101"<br /><br />查询所有版本：<br />scan 'ns1:test', {RAW =&gt; true, VERSIONS =&gt; 10}<br /><br />scan:(扫描表所有数据)<br />scan 'ns1:test',{COLUMNS=&gt;["info:name","info:age"]}<br />scan 'ns1:test',{COLUMNS=&gt;["info:name","info:age"],STARTROW=&gt;'rk5',LIMIT=&gt;2}<br /><br />get:(查询一行数据)<br />get 'ns1:test','rk1',{COLUMNS=&gt;["info:name","info:age"],TIMESTAMP =&gt; 1504884343447}<br />###取具体版本：<br />get 'ns1:test','rk1',{COLUMNS=&gt;["info:name","info:age"],VERSIONS =&gt; 3}<br /><br /><br />删除：<br />delete 'ns1:test','rk1','info:age'<br />deleteall 'ns1:test','rk1'<br /><br />表是否存在：<br />exists 'ns1:test'<br />disable 'ns1:test'<br />enable 'ns1:test'<br />desc 'ns1:test'<br /><br />count 'ns1:test'<br />truncate 'ns1:test'<br /><br />#<br />drop 'ns1:test'<br /><br /><br /><br /><br />hbase 应用？？<br />NameSpaceDescriptor<br />HtableDescriptor<br />HColumnDescriptor<br />HbaseConfiguration<br />Connection<br />ConnectionFactory<br />HbaseAdmin/Admin  (ddl操作几乎用它)<br /><br />put<br />get<br />scan<br />delete<br />drop<br />tableExists()<br />isEnable()<br />isDisable()<br /><br />过滤器：<br />FilterList<br />SingleColumnValueFilter<br />字符串二进制比较：<br />比较器比较：<br />BinaryCompartor<br />BinaryPrefixCompartor<br />RegexStringCompartor<br />SubStringCompartor<br /><br />FamilyFilter<br />RowFilter<br />QualifierFilter<br />ColumnPrefixFilter<br />ColumnRangeFilter<br />MultipleColumnPrefixFilter<br />FirstKeyOnlyFilter<br /><br /><br />hbase和mapreduce的整合：<br />TableMapper<br />TableReducer或者普通的Reduce  (两种方式)<br />TableMapReduceUtil.init<br /><br /><br />####hbase和hive的整合<br />整合的意义：<br /><br />整合的目的：<br />habse中的表的数据在hive中能看到：<br />hive中表的数据在hbase中能看到：<br /><br />1、在hive中创建hbase能看到的表：<br />create table if not exists habsehive(<br />uid int,<br />uname String<br />)<br />stored by 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'<br />with serdeproperties("hbase.columns.mapping"=":key,cf1:uname")<br />tblproperties("hbase.table.name"="hh2")<br />;<br /><br />##出现如下错误：<br />FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. <br />org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V<br /><br />解决方法：<br />将源码包重新打包<br /><br /><br />##加载数据：insert into (不能用load方式)<br />create table if not exists habsehivetmp(<br />uid int,<br />uname String<br />)<br />row format delimited fields terminated by ' '<br />;<br /><br />load data local inpath '/home/hhdata' into table habsehivetmp;<br /><br />insert into table habsehive<br />select uid,uname from habsehivetmp<br />;<br /><br /><br />2、对于hbase已经右表，并且存在数据：<br />create external table if not exists habsehive1(<br />age int,<br />count int<br />)<br />stored by 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'<br />with serdeproperties("hbase.columns.mapping"=":key,data:ageCount")<br />tblproperties("hbase.table.name"="ns1:result")<br />;<br /><br /><br />3、映射多列：<br />create external table if not exists habsehive3(<br />uid string,<br />uname string,<br />uage int,<br />usex int<br />)<br />stored by 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'<br />with serdeproperties("hbase.columns.mapping"=":key,info:name,info:age,info:sex")<br />tblproperties("hbase.table.name"="ns1:user")<br />;<br /><br /><br />注意：<br />映射hbase中的列，要写就是:key，要么不写。否则列数不匹配，因为默认使用:key<br />hbase中表存在的时候，在hive中创建对应表的时候需要加关键字external。<br />若删除hbase中的对应数据，在hive中就不能查询出来数据。<br />hbase中的列和hive中的列个数和类型尽量相同(hive和hbase表中的字段不是按照名字匹配，是按照顺序来匹配)<br />hive和hbase、mysql等可以使用第三方工具来相互整合数据。如蓝灯、shell脚本等。<br /><br /><br />？？？将mysql中的数据通过sqoop导入的hbase中？？？<br /><br /><br />hbase需要注意的事项：<br />属性设置：<br />memstore刷新的阀值：<br />hbase.hregion.memstore.flush.size=134217728  128M<br />hrgion切分阀值：<br />hbase.hregion.max.filesize=10737418240  10G<br />regionser的操作线程数：<br />hbase.regionserver.handler.count=30<br /><br />客户端的优化：<br />1、关闭自动刷新<br />ht.setAutoFlush(false, true);  //设置是否自动刷新，默认是自动刷新<br />2、尽量批量写入  (put或者delete的时候尽量批量写入)<br />3、谨慎关闭写Hlog：<br />hd.setDurability(Durability.SKIP_WAL);<br />4、尽量把数据放到缓存里面：<br />hc.setInMemory(true);<br />5、尽量不要太多的列簇，最多两个。<br />因为在hbase刷新数据的时候将会引起该列簇附近的列簇刷新。<br />6、rowkey的长度尽量短。最大64KB<br />7、尽量将该关闭的对象关闭。比如：admin 、table 、 ResultScaner 、 HbaseAdmin 等。<br /><br /><br /><br />row-key设计有两种：<br />user: age uname sex hight weight add wedding<br />wap : <br />统计每月每一款游戏的哪个装备较好？？<br />统计每个月哪个玩家使用某个装备数较多？？<br />game_timeStamp  zb:次数<br />user_timestamp_game game: , zb: <br />game_timeStamp user: ,  <br /><br /><br />宽表：<br />高表：<br /><br /><br />作业：<br />1、建立部门表：<br />	要求：<br />		部门下有多个子部门。<br />		查询所有的顶级部门列表，<br />		查询某个部门下所有子部门列表（不要求递归），<br />		可以修改一个部门的所属父部门。<br />		<br />2、建立学生和课程表<br />	要求：学生可以选择多个课程，每个课程可以被多个学生选择。<br />		查询某个学生所选的所有课程列表<br />		查询某个课程，的学生列表<br />		学生可以修改所选的课程<br /><br />		<br />单机环境，4G内存？？<br />a和b两个文件：<br />每个文件50亿行url，每行url是64KB<br />怎么快速查找a文件中的每个url在b文件中提取出来。<br /><br /><br /></div></div>
</body></html>