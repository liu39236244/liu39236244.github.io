æˆ‘æ¥å¸®ä½ ç”¨ Go é‡æ„è¿™ä¸ªè„šæœ¬ã€‚Go åœ¨å¹¶å‘å¤„ç†å’Œå†…å­˜ç®¡ç†æ–¹é¢ç¡®å®æœ‰ä¼˜åŠ¿ï¼Œæˆ‘ä¼šå……åˆ†åˆ©ç”¨ Go çš„ç‰¹æ€§æ¥ä¼˜åŒ–æ€§èƒ½ã€‚

```go
package main

import (
	"database/sql"
	"encoding/json"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"os/signal"
	"path/filepath"
	"strconv"
	"strings"
	"sync"
	"syscall"
	"time"

	"github.com/go-sql-driver/mysql"
	"github.com/schollz/progressbar/v3"
	"github.com/xitongsys/parquet-go-source/local"
	"github.com/xitongsys/parquet-go/parquet"
	"github.com/xitongsys/parquet-go/writer"
)

// ==============================================================================
// 1. é…ç½®ç»“æ„ä½“
// ==============================================================================

type Config struct {
	// æ•°æ®åº“é…ç½®
	DBHost     string `json:"db_host"`
	DBPort     int    `json:"db_port"`
	DBUser     string `json:"db_user"`
	DBPassword string `json:"db_password"`
	DBName     string `json:"db_name"`

	// åŸºç¡€é…ç½®
	BaseTableName string `json:"base_table_name"`
	YearMonth     string `json:"year_month"`
	StartDate     string `json:"start_date"`
	EndDate       string `json:"end_date"`
	OutputFolder  string `json:"output_folder"`

	// æ€§èƒ½å‚æ•°
	MaxParallelTables int `json:"max_parallel_tables"`
	ReadBatchSize     int `json:"read_batch_size"`
	RowsPerFile       int `json:"rows_per_file"`

	// æ•°æ®åº“è¿æ¥æ± é…ç½®
	MaxIdleConns    int           `json:"max_idle_conns"`
	MaxOpenConns    int           `json:"max_open_conns"`
	ConnMaxLifetime time.Duration `json:"conn_max_lifetime"`

	// é«˜çº§å‚æ•°
	QueueMaxBatches int `json:"queue_max_batches"`
	DBReadRetries   int `json:"db_read_retries"`
	DBRetryDelay    int `json:"db_retry_delay"`
}

// é»˜è®¤é…ç½®
func getDefaultConfig() *Config {
	return &Config{
		DBHost:            "10.110.34.60",
		DBPort:            9030,
		DBUser:            "bridge_30_user_a",
		DBPassword:        "gsxzTASJ99",
		DBName:            "bridge_history_data_30",
		BaseTableName:     "probe_data_30",
		YearMonth:         "2024-09",
		StartDate:         "2024-09-01",
		EndDate:           "2024-09-30",
		OutputFolder:      "E:\\parquet\\30",
		MaxParallelTables: 4,
		ReadBatchSize:     30000,
		RowsPerFile:       200000,
		MaxIdleConns:      5,
		MaxOpenConns:      10, // æ§åˆ¶æœ€å¤§è¿æ¥æ•°ï¼Œé¿å…ç»™æ•°æ®åº“é€ æˆå‹åŠ›
		ConnMaxLifetime:   time.Hour,
		QueueMaxBatches:   10,
		DBReadRetries:     5,
		DBRetryDelay:      5,
	}
}

// ==============================================================================
// 2. æ•°æ®ç»“æ„å®šä¹‰
// ==============================================================================

// æ•°æ®è¡Œç»“æ„ä½“ - æ ¹æ®ä½ çš„å®é™…è¡¨ç»“æ„è°ƒæ•´
type DataRow struct {
	ID        int64     `parquet:"name=id, type=INT64"`
	Timestamp time.Time `parquet:"name=timestamp, type=TIMESTAMP_MILLIS"`
	Value     float64   `parquet:"name=value, type=DOUBLE"`
	// æ·»åŠ å…¶ä»–å­—æ®µ...
}

// æ£€æŸ¥ç‚¹ç»“æ„ä½“
type CheckpointData struct {
	LastProcessedID int64  `json:"last_processed_id"`
	NextFileIndex   int    `json:"next_file_index"`
	LastUpdateTime  string `json:"last_update_time"`
}

type Checkpoint struct {
	filepath string
	data     map[string]*CheckpointData
	mutex    sync.RWMutex
}

// ä»»åŠ¡ç»“æœ
type TaskResult struct {
	TableName    string
	RowsWritten  int64
	Success      bool
	ErrorMessage string
}

// ==============================================================================
// 3. å…¨å±€å˜é‡å’Œåˆå§‹åŒ–
// ==============================================================================

var (
	config       *Config
	db           *sql.DB
	shutdownChan = make(chan os.Signal, 1)
	isShutdown   = make(chan struct{})
	wg           sync.WaitGroup
)

func init() {
	// æ•è·ä¸­æ–­ä¿¡å·
	signal.Notify(shutdownChan, os.Interrupt, syscall.SIGTERM)
	go func() {
		<-shutdownChan
		fmt.Println("\n\nâš ï¸  æ•è·åˆ°ä¸­æ–­ä¿¡å·... æ­£åœ¨è¯·æ±‚æ‰€æœ‰ä»»åŠ¡ä¼˜é›…é€€å‡º...")
		close(isShutdown)
	}()
}

// ==============================================================================
// 4. æ£€æŸ¥ç‚¹ç®¡ç†å™¨
// ==============================================================================

func NewCheckpoint(filepath string) (*Checkpoint, error) {
	cp := &Checkpoint{
		filepath: filepath,
		data:     make(map[string]*CheckpointData),
	}

	// å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºç©ºæ–‡ä»¶
	if _, err := os.Stat(filepath); os.IsNotExist(err) {
		if err := cp.save(); err != nil {
			return nil, fmt.Errorf("æ— æ³•åˆ›å»ºæ£€æŸ¥ç‚¹æ–‡ä»¶: %v", err)
		}
	} else {
		if err := cp.load(); err != nil {
			log.Printf("âš ï¸ è­¦å‘Š: æ— æ³•åŠ è½½æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œå°†é‡æ–°å¼€å§‹: %v", err)
		}
	}

	return cp, nil
}

func (cp *Checkpoint) load() error {
	cp.mutex.Lock()
	defer cp.mutex.Unlock()

	data, err := ioutil.ReadFile(cp.filepath)
	if err != nil {
		return err
	}

	if len(data) == 0 {
		return nil
	}

	return json.Unmarshal(data, &cp.data)
}

func (cp *Checkpoint) save() error {
	cp.mutex.RLock()
	data, err := json.MarshalIndent(cp.data, "", "    ")
	cp.mutex.RUnlock()

	if err != nil {
		return err
	}

	// åŸå­å†™å…¥
	tempFile := cp.filepath + ".tmp"
	if err := ioutil.WriteFile(tempFile, data, 0644); err != nil {
		return err
	}

	return os.Rename(tempFile, cp.filepath)
}

func (cp *Checkpoint) GetProgress(tableName string) *CheckpointData {
	cp.mutex.RLock()
	defer cp.mutex.RUnlock()

	if data, exists := cp.data[tableName]; exists {
		return data
	}

	return &CheckpointData{
		LastProcessedID: 0,
		NextFileIndex:   0,
	}
}

func (cp *Checkpoint) UpdateProgress(tableName string, lastID int64, fileIndex int) error {
	cp.mutex.Lock()
	cp.data[tableName] = &CheckpointData{
		LastProcessedID: lastID,
		NextFileIndex:   fileIndex,
		LastUpdateTime:  time.Now().Format(time.RFC3339),
	}
	cp.mutex.Unlock()

	return cp.save()
}

func (cp *Checkpoint) IsTableCompleted(tableName string, maxID int64) bool {
	if maxID == 0 {
		return true
	}
	return cp.GetProgress(tableName).LastProcessedID >= maxID
}

// ==============================================================================
// 5. æ•°æ®åº“æ“ä½œ
// ==============================================================================

func initDB() error {
	// æ„å»º DSN
	cfg := mysql.Config{
		User:                 config.DBUser,
		Passwd:               config.DBPassword,
		Net:                  "tcp",
		Addr:                 fmt.Sprintf("%s:%d", config.DBHost, config.DBPort),
		DBName:               config.DBName,
		ParseTime:            true,
		Timeout:              30 * time.Second,
		ReadTimeout:          60 * time.Second,
		WriteTimeout:         60 * time.Second,
		AllowNativePasswords: true,
	}

	var err error
	db, err = sql.Open("mysql", cfg.FormatDSN())
	if err != nil {
		return fmt.Errorf("æ— æ³•è¿æ¥æ•°æ®åº“: %v", err)
	}

	// é…ç½®è¿æ¥æ±  - å…³é”®ä¼˜åŒ–ç‚¹ï¼Œé¿å…ç»™StarRocksé€ æˆå‹åŠ›
	db.SetMaxOpenConns(config.MaxOpenConns)
	db.SetMaxIdleConns(config.MaxIdleConns)
	db.SetConnMaxLifetime(config.ConnMaxLifetime)

	// æµ‹è¯•è¿æ¥
	if err := db.Ping(); err != nil {
		return fmt.Errorf("æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: %v", err)
	}

	fmt.Printf("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ (æœ€å¤§è¿æ¥æ•°: %d)\n", config.MaxOpenConns)
	return nil
}

func getMaxID(tableName string) (int64, error) {
	query := fmt.Sprintf("SELECT MAX(id) FROM `%s`", tableName)
	var maxID sql.NullInt64

	err := db.QueryRow(query).Scan(&maxID)
	if err != nil {
		return 0, err
	}

	if !maxID.Valid {
		return 0, nil
	}

	return maxID.Int64, nil
}

func tableExists(tableName string) bool {
	query := "SELECT 1 FROM information_schema.tables WHERE table_schema = ? AND table_name = ? LIMIT 1"
	var exists int
	err := db.QueryRow(query, config.DBName, tableName).Scan(&exists)
	return err == nil
}

// ==============================================================================
// 6. æ•°æ®è¯»å–å™¨ (ç”Ÿäº§è€…)
// ==============================================================================

func dataReader(tableName string, startID, maxID int64, dataChan chan<- []DataRow, errorChan chan<- error) {
	defer close(dataChan)

	currentID := startID
	retries := 0

	for currentID < maxID {
		select {
		case <-isShutdown:
			return
		default:
		}

		upperBound := currentID + int64(config.ReadBatchSize)
		if upperBound > maxID {
			upperBound = maxID
		}

		query := fmt.Sprintf("SELECT id, timestamp, value FROM `%s` WHERE id > ? AND id <= ? ORDER BY id", tableName)

		rows, err := db.Query(query, currentID, upperBound)
		if err != nil {
			retries++
			if retries > config.DBReadRetries {
				errorChan <- fmt.Errorf("æ•°æ®åº“è¯»å–å¤±è´¥æ¬¡æ•°è¿‡å¤š: %v", err)
				return
			}
			log.Printf("âš ï¸ [%s] æ•°æ®åº“è¯»å–é”™è¯¯: %vï¼Œå°†åœ¨ %d ç§’åé‡è¯•...", tableName, err, config.DBRetryDelay)
			time.Sleep(time.Duration(config.DBRetryDelay) * time.Second)
			continue
		}

		var batch []DataRow
		for rows.Next() {
			var row DataRow
			if err := rows.Scan(&row.ID, &row.Timestamp, &row.Value); err != nil {
				rows.Close()
				errorChan <- fmt.Errorf("æ‰«ææ•°æ®è¡Œå¤±è´¥: %v", err)
				return
			}
			batch = append(batch, row)
		}
		rows.Close()

		if len(batch) > 0 {
			select {
			case dataChan <- batch:
				retries = 0 // é‡ç½®é‡è¯•è®¡æ•°
			case <-isShutdown:
				return
			}
		}

		currentID = upperBound
	}
}

// ==============================================================================
// 7. æ–‡ä»¶å†™å…¥å™¨ (æ¶ˆè´¹è€…)
// ==============================================================================

func fileWriter(tableName string, maxID int64, checkpoint *Checkpoint, dataChan <-chan []DataRow, 
	tablePath string, resultChan chan<- TaskResult) {
	
	var totalRowsWritten int64
	success := true
	var errorMsg string

	progress := checkpoint.GetProgress(tableName)
	fileIndex := progress.NextFileIndex

	// åˆ›å»ºè¿›åº¦æ¡
	bar := progressbar.NewOptions64(maxID,
		progressbar.OptionSetDescription(fmt.Sprintf("è¡¨ %-20s", filepath.Base(tableName))),
		progressbar.OptionSetWidth(50),
		progressbar.OptionShowCount(),
		progressbar.OptionSetRenderBlankState(true),
	)
	bar.Set64(progress.LastProcessedID)

	defer func() {
		bar.Finish()
		resultChan <- TaskResult{
			TableName:    tableName,
			RowsWritten:  totalRowsWritten,
			Success:      success,
			ErrorMessage: errorMsg,
		}
	}()

	var fileBuffer []DataRow
	var lastProcessedID int64 = progress.LastProcessedID

	for {
		select {
		case batch, ok := <-dataChan:
			if !ok {
				// æ•°æ®é€šé“å…³é—­ï¼Œå¤„ç†å‰©ä½™ç¼“å†²åŒºæ•°æ®
				if len(fileBuffer) > 0 {
					if err := writeParquetFile(tablePath, tableName, fileIndex, fileBuffer); err != nil {
						success = false
						errorMsg = fmt.Sprintf("å†™å…¥æœ€åä¸€ä¸ªæ–‡ä»¶å¤±è´¥: %v", err)
						return
					}
					
					// æ›´æ–°æ£€æŸ¥ç‚¹
					maxIDInBuffer := getMaxIDFromBuffer(fileBuffer)
					checkpoint.UpdateProgress(tableName, maxIDInBuffer, fileIndex+1)
					totalRowsWritten += int64(len(fileBuffer))
				}
				return
			}

			fileBuffer = append(fileBuffer, batch...)
			
			// æ›´æ–°æœ€åå¤„ç†çš„ID
			if len(batch) > 0 {
				lastProcessedID = batch[len(batch)-1].ID
				bar.Set64(lastProcessedID)
			}

			// æ£€æŸ¥æ˜¯å¦éœ€è¦å†™å…¥æ–‡ä»¶
			if len(fileBuffer) >= config.RowsPerFile {
				if err := writeParquetFile(tablePath, tableName, fileIndex, fileBuffer); err != nil {
					success = false
					errorMsg = fmt.Sprintf("å†™å…¥æ–‡ä»¶å¤±è´¥: %v", err)
					return
				}

				// æ›´æ–°æ£€æŸ¥ç‚¹
				maxIDInBuffer := getMaxIDFromBuffer(fileBuffer)
				checkpoint.UpdateProgress(tableName, maxIDInBuffer, fileIndex+1)
				
				totalRowsWritten += int64(len(fileBuffer))
				fileIndex++
				fileBuffer = nil // æ¸…ç©ºç¼“å†²åŒº

				// æ‰‹åŠ¨è§¦å‘GCï¼Œæ§åˆ¶å†…å­˜ä½¿ç”¨
				if fileIndex%10 == 0 {
					runtime.GC()
				}
			}

		case <-isShutdown:
			return
		}
	}
}

func writeParquetFile(tablePath, tableName string, fileIndex int, data []DataRow) error {
	filename := fmt.Sprintf("%s_%d.parquet", tableName, fileIndex)
	filepath := filepath.Join(tablePath, filename)

	fw, err := local.NewLocalFileWriter(filepath)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºæ–‡ä»¶å†™å…¥å™¨å¤±è´¥: %v", err)
	}
	defer fw.Close()

	// åˆ›å»º Parquet å†™å…¥å™¨
	pw, err := writer.NewParquetWriter(fw, new(DataRow), 4)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºParquetå†™å…¥å™¨å¤±è´¥: %v", err)
	}
	defer pw.WriteStop()

	// è®¾ç½®å‹ç¼©
	pw.CompressionType = parquet.CompressionCodec_SNAPPY

	// å†™å…¥æ•°æ®
	for _, row := range data {
		if err := pw.Write(row); err != nil {
			return fmt.Errorf("å†™å…¥æ•°æ®è¡Œå¤±è´¥: %v", err)
		}
	}

	return nil
}

func getMaxIDFromBuffer(buffer []DataRow) int64 {
	if len(buffer) == 0 {
		return 0
	}
	
	maxID := buffer[0].ID
	for _, row := range buffer[1:] {
		if row.ID > maxID {
			maxID = row.ID
		}
	}
	return maxID
}

// ==============================================================================
// 8. è¡¨å¤„ç†å™¨
// ==============================================================================

func processTable(tableName string, checkpoint *Checkpoint, position int) TaskResult {
	// åˆ›å»ºè¡¨ç›®å½•
	basePath := filepath.Join(config.OutputFolder, fmt.Sprintf("%s_%s", config.BaseTableName, config.YearMonth))
	tablePath := filepath.Join(basePath, tableName)
	
	if err := os.MkdirAll(tablePath, 0755); err != nil {
		return TaskResult{
			TableName:    tableName,
			Success:      false,
			ErrorMessage: fmt.Sprintf("åˆ›å»ºç›®å½•å¤±è´¥: %v", err),
		}
	}

	// è·å–è¡¨çš„æœ€å¤§ID
	maxID, err := getMaxID(tableName)
	if err != nil {
		return TaskResult{
			TableName:    tableName,
			Success:      false,
			ErrorMessage: fmt.Sprintf("è·å–æœ€å¤§IDå¤±è´¥: %v", err),
		}
	}

	// æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
	startID := checkpoint.GetProgress(tableName).LastProcessedID
	if startID >= maxID && maxID > 0 {
		return TaskResult{
			TableName:   tableName,
			Success:     true,
			RowsWritten: 0,
		}
	}

	// åˆ›å»ºé€šé“
	dataChan := make(chan []DataRow, config.QueueMaxBatches)
	errorChan := make(chan error, 1)
	resultChan := make(chan TaskResult, 1)

	// å¯åŠ¨è¯»å–å™¨ (ç”Ÿäº§è€…)
	go dataReader(tableName, startID, maxID, dataChan, errorChan)

	// å¯åŠ¨å†™å…¥å™¨ (æ¶ˆè´¹è€…)
	go fileWriter(tableName, maxID, checkpoint, dataChan, tablePath, resultChan)

	// ç­‰å¾…å®Œæˆæˆ–é”™è¯¯
	select {
	case err := <-errorChan:
		return TaskResult{
			TableName:    tableName,
			Success:      false,
			ErrorMessage: err.Error(),
		}
	case result := <-resultChan:
		return result
	case <-isShutdown:
		return TaskResult{
			TableName:    tableName,
			Success:      false,
			ErrorMessage: "ä»»åŠ¡è¢«ä¸­æ–­",
		}
	}
}

// ==============================================================================
// 9. ä¸»å‡½æ•°
// ==============================================================================

func main() {
	startTime := time.Now()

	// åŠ è½½é…ç½®
	config = getDefaultConfig()
	
	// åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
	if err := initDB(); err != nil {
		log.Fatalf("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: %v", err)
	}
	defer db.Close()

	// åˆ›å»ºè¾“å‡ºç›®å½•
	basePath := filepath.Join(config.OutputFolder, fmt.Sprintf("%s_%s", config.BaseTableName, config.YearMonth))
	if err := os.MkdirAll(basePath, 0755); err != nil {
		log.Fatalf("âŒ åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %v", err)
	}

	// åˆå§‹åŒ–æ£€æŸ¥ç‚¹
	checkpointFile := filepath.Join(basePath, "checkpoint.json")
	checkpoint, err := NewCheckpoint(checkpointFile)
	if err != nil {
		log.Fatalf("âŒ åˆå§‹åŒ–æ£€æŸ¥ç‚¹å¤±è´¥: %v", err)
	}

	// ç”Ÿæˆè¡¨ååˆ—è¡¨
	startDate, _ := time.Parse("2006-01-02", config.StartDate)
	endDate, _ := time.Parse("2006-01-02", config.EndDate)
	
	var allTables []string
	for d := startDate; !d.After(endDate); d = d.AddDate(0, 0, 1) {
		tableName := fmt.Sprintf("%s_%s", config.BaseTableName, d.Format("2006_01_02"))
		allTables = append(allTables, tableName)
	}

	// é¢„æ£€æŸ¥è¡¨çŠ¶æ€
	fmt.Println("--- é¢„æ£€æŸ¥è¡¨çŠ¶æ€ ---")
	var tablesToProcess []string
	
	checkBar := progressbar.NewOptions(len(allTables),
		progressbar.OptionSetDescription("æ£€æŸ¥è¡¨çŠ¶æ€"),
		progressbar.OptionSetWidth(50),
	)

	for _, tableName := range allTables {
		select {
		case <-isShutdown:
			fmt.Println("\nå¯åŠ¨è¿‡ç¨‹ä¸­æ£€æµ‹åˆ°é€€å‡ºä¿¡å·ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
			return
		default:
		}

		if tableExists(tableName) {
			maxID, err := getMaxID(tableName)
			if err == nil && !checkpoint.IsTableCompleted(tableName, maxID) {
				tablesToProcess = append(tablesToProcess, tableName)
			}
		}
		checkBar.Add(1)
	}
	checkBar.Finish()

	if len(tablesToProcess) == 0 {
		fmt.Println("\nğŸ‰ æ‰€æœ‰æŒ‡å®šèŒƒå›´å†…çš„è¡¨å‡å·²å¤„ç†å®Œæˆï¼")
		return
	}

	fmt.Printf("\nå‘ç° %d å¼ å¾…å¤„ç†çš„è¡¨ã€‚å°†ä½¿ç”¨ %d ä¸ªå¹¶å‘ä»»åŠ¡å¼€å§‹å¤„ç†...\n", 
		len(tablesToProcess), config.MaxParallelTables)
	time.Sleep(2 * time.Second)

	// ä½¿ç”¨ worker pool æ¨¡å¼å¤„ç†è¡¨
	taskChan := make(chan string, len(tablesToProcess))
	resultChan := make(chan TaskResult, len(tablesToProcess))

	// å‘é€ä»»åŠ¡
	for _, tableName := range tablesToProcess {
		taskChan <- tableName
	}
	close(taskChan)

	// å¯åŠ¨ worker
	for i := 0; i < config.MaxParallelTables; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			for tableName := range taskChan {
				select {
				case <-isShutdown:
					return
				default:
					result := processTable(tableName, checkpoint, workerID)
					resultChan <- result
				}
			}
		}(i)
	}

	// ç­‰å¾…æ‰€æœ‰ worker å®Œæˆ
	go func() {
		wg.Wait()
		close(resultChan)
	}()

	// æ”¶é›†ç»“æœ
	var totalRowsProcessed int64
	successCount := 0
	
	for result := range resultChan {
		if result.Success {
			totalRowsProcessed += result.RowsWritten
			successCount++
		} else {
			fmt.Printf("\nâš ï¸  è¡¨ %s å¤„ç†å¤±è´¥: %s\n", result.TableName, result.ErrorMessage)
		}
	}

	// è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
	fmt.Printf("\n" + strings.Repeat("=", 80) + "\n")
	fmt.Printf("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæ¯•ï¼\n")
	fmt.Printf("â±ï¸  æ€»è€—æ—¶: %.2f ç§’\n", time.Since(startTime).Seconds())
	fmt.Printf("ğŸ’¾ æœ¬æ¬¡è¿è¡Œæ€»å…±å†™å…¥è¡Œæ•°: %s\n", formatNumber(totalRowsProcessed))
	fmt.Printf("âœ… æˆåŠŸå¤„ç†è¡¨æ•°: %d/%d\n", successCount, len(tablesToProcess))
	fmt.Printf("ğŸ“ æ–­ç‚¹æ–‡ä»¶ä½ç½®: %s\n", checkpointFile)
	fmt.Printf(strings.Repeat("=", 80) + "\n")
}

// è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–æ•°å­—
func formatNumber(n int64) string {
	str := strconv.FormatInt(n, 10)
	if len(str) <= 3 {
		return str
	}
	
	var result []rune
	for i, r := range str {
		if i > 0 && (len(str)-i)%3 == 0 {
			result = append(result, ',')
		}
		result = append(result, r)
	}
	return string(result)
}
```

è¿˜éœ€è¦åˆ›å»ºä¸€ä¸ª `go.mod` æ–‡ä»¶ï¼š

```go
module starrocks-exporter

go 1.19

require (
    github.com/go-sql-driver/mysql v1.7.1
    github.com/schollz/progressbar/v3 v3.13.1
    github.com/xitongsys/parquet-go v1.6.2
    github.com/xitongsys/parquet-go-source v0.0.0-20230607234618-40034c8066df
)
```

## ä¸»è¦æ”¹è¿›å’Œ Go ç‰¹æ€§åº”ç”¨ï¼š

### 1. **å¹¶å‘æ¨¡å‹ä¼˜åŒ–**
- ä½¿ç”¨ Go çš„ goroutine æ›¿ä»£ Python çš„çº¿ç¨‹ï¼Œæ›´è½»é‡çº§
- é‡‡ç”¨ channel è¿›è¡Œ goroutine é—´é€šä¿¡ï¼Œé¿å…é”ç«äº‰
- ä½¿ç”¨ worker pool æ¨¡å¼ï¼Œæ›´å¥½åœ°æ§åˆ¶å¹¶å‘æ•°

### 2. **å†…å­˜ç®¡ç†ä¼˜åŒ–**
- æ˜¾å¼è°ƒç”¨ `runtime.GC()` æ§åˆ¶å†…å­˜å›æ”¶
- ä½¿ç”¨ slice è€Œä¸æ˜¯åŠ¨æ€æ•°ç»„ï¼Œå‡å°‘å†…å­˜åˆ†é…
- åŠæ—¶é‡Šæ”¾æ•°æ®åº“è¿æ¥å’Œæ–‡ä»¶å¥æŸ„

### 3. **æ•°æ®åº“è¿æ¥ä¼˜åŒ–**
- ä¸¥æ ¼æ§åˆ¶æœ€å¤§è¿æ¥æ•°ï¼Œé¿å…ç»™ StarRocks é€ æˆå‹åŠ›
- è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
- ä½¿ç”¨è¿æ¥æ± å¤ç”¨è¿æ¥

### 4. **é”™è¯¯å¤„ç†å’Œæ¢å¤**
- å®Œæ•´çš„é”™è¯¯ä¼ æ’­æœºåˆ¶
- ä¼˜é›…çš„ä¿¡å·å¤„ç†å’Œé€€å‡º
- æ–­ç‚¹ç»­ä¼ åŠŸèƒ½ä¿æŒå®Œæ•´

### 5. **æ€§èƒ½ç›‘æ§**
- ä½¿ç”¨ progressbar åº“æä¾›å®æ—¶è¿›åº¦æ˜¾ç¤º
- è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯è¾“å‡º

## ä½¿ç”¨æ–¹æ³•ï¼š

1. **å®‰è£…ä¾èµ–**ï¼š
```bash
go mod tidy
```

2. **è¿è¡Œç¨‹åº**ï¼š
```bash
go run main.go
```

3. **ç¼–è¯‘ä¸ºå¯æ‰§è¡Œæ–‡ä»¶**ï¼š
```bash
go build -o starrocks-exporter main.go
```
## åˆå§‹åŒ–


æ˜¯çš„ï¼ŒGoçš„`.mod`æ–‡ä»¶é€šå¸¸æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œä½†éœ€è¦ä½ å…ˆåˆå§‹åŒ–æ¨¡å—ã€‚è®©æˆ‘å¸®ä½ åˆ›å»ºæ­£ç¡®çš„Goæ¨¡å—ç»“æ„ã€‚

## 1. åˆå§‹åŒ–Goæ¨¡å—

åœ¨ä½ çš„é¡¹ç›®ç›®å½•ä¸­è¿è¡Œï¼š

```bash
go mod init your-project-name
```

ä¾‹å¦‚ï¼š
```bash
go mod init parquet-exporter
```

## 2. è‡ªåŠ¨ç”Ÿæˆçš„ go.mod æ–‡ä»¶

è¿è¡Œä¸Šè¿°å‘½ä»¤åï¼Œä¼šç”Ÿæˆä¸€ä¸ªåŸºç¡€çš„ `go.mod` æ–‡ä»¶ï¼š

```go
module parquet-exporter

go 1.21
```

## 3. å®‰è£…ä¾èµ–åŒ…

ç„¶åè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥è‡ªåŠ¨ä¸‹è½½å’Œæ·»åŠ ä¾èµ–ï¼š

```bash
go mod tidy
```

è¿™ä¼šåˆ†æä½ çš„ä»£ç ä¸­çš„importè¯­å¥ï¼Œè‡ªåŠ¨ä¸‹è½½æ‰€éœ€çš„åŒ…ï¼Œå¹¶æ›´æ–°`go.mod`æ–‡ä»¶ã€‚

## 4. æœ€ç»ˆçš„ go.mod æ–‡ä»¶

è¿è¡Œ `go mod tidy` åï¼Œä½ çš„ `go.mod` æ–‡ä»¶åº”è¯¥ç±»ä¼¼è¿™æ ·ï¼š

```go
module parquet-exporter

go 1.21

require (
	github.com/go-sql-driver/mysql v1.7.1
	github.com/schollz/progressbar/v3 v3.14.1
	github.com/xitongsys/parquet-go v1.6.2
	github.com/xitongsys/parquet-go-source v0.0.0-20230919062804-c82e7a1e7c6c
)

require (
	github.com/apache/arrow/go/arrow v0.0.0-20211112161151-bc219186db40 // indirect
	github.com/apache/thrift v0.16.0 // indirect
	github.com/klauspost/compress v1.15.9 // indirect
	github.com/mitchellh/colorstring v0.0.0-20190213212951-d06e56a500db // indirect
	github.com/pierrec/lz4/v4 v4.1.8 // indirect
	github.com/rivo/uniseg v0.4.4 // indirect
	golang.org/x/sys v0.14.0 // indirect
	golang.org/x/term v0.14.0 // indirect
	golang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1 // indirect
)
```

## 5. å®Œæ•´çš„æ“ä½œæ­¥éª¤

```bash
# 1. è¿›å…¥ä½ çš„é¡¹ç›®ç›®å½•
cd /path/to/your/project

# 2. åˆå§‹åŒ–Goæ¨¡å—
go mod init parquet-exporter

# 3. å°†ä½ çš„ä»£ç ä¿å­˜ä¸º main.go

# 4. è‡ªåŠ¨ä¸‹è½½ä¾èµ–å¹¶ç”Ÿæˆå®Œæ•´çš„modæ–‡ä»¶
go mod tidy

# 5. è¿è¡Œç¨‹åº
go run main.go
```

## 6. å¯èƒ½é‡åˆ°çš„é—®é¢˜

å¦‚æœæŸäº›åŒ…æ— æ³•ä¸‹è½½ï¼Œå¯èƒ½éœ€è¦è®¾ç½®Goä»£ç†ï¼š

```bash
# è®¾ç½®Goä»£ç†ï¼ˆä¸­å›½ç”¨æˆ·æ¨èï¼‰
go env -w GOPROXY=https://goproxy.cn,direct
go env -w GOSUMDB=sum.golang.google.cn

# ç„¶åé‡æ–°è¿è¡Œ
go mod tidy
```

## 7. é¡¹ç›®ç»“æ„å»ºè®®

```
your-project/
â”œâ”€â”€ go.mod          # è‡ªåŠ¨ç”Ÿæˆ
â”œâ”€â”€ go.sum          # è‡ªåŠ¨ç”Ÿæˆ
â”œâ”€â”€ main.go         # ä½ çš„ä¸»ç¨‹åº
â”œâ”€â”€ config.json     # å¯é€‰çš„é…ç½®æ–‡ä»¶
â””â”€â”€ README.md       # é¡¹ç›®è¯´æ˜
```

è¿™æ ·ï¼ŒGoä¼šè‡ªåŠ¨ç®¡ç†ä½ çš„ä¾èµ–å…³ç³»ï¼Œä½ å°±ä¸éœ€è¦æ‰‹åŠ¨ç»´æŠ¤`.mod`æ–‡ä»¶äº†ã€‚æ¯æ¬¡æ·»åŠ æ–°çš„importæˆ–è¿è¡Œ`go mod tidy`æ—¶ï¼ŒGoéƒ½ä¼šè‡ªåŠ¨æ›´æ–°ä¾èµ–ä¿¡æ¯ã€‚