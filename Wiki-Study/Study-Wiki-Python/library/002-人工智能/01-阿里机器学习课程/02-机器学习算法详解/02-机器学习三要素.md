

# 机器学习方法三要素

二、模型

三、策略


## 一、机器学习方法三要素

机器学习方法通常都是由模型、策略和算法三部分构成:方法=模型+策略+算法

（1）模型:输入空间到输出空间的映射关系。学习过程即为从假设空间中搜索适合当前数据的假设。

（2）策略:从假设空间众多的假设中选择到最优的模型的学习标准或规则。

（3）算法:学习模型的具体的计算方法，通常是求解最优化问题。



 ![](assets/002/01/02/02-1684140338581.png)


 ### 二、模型

模型:输入空间到输出空间的映射关系。学习过程即为从假设空间中搜索适合当前数据的假设。分析当前需要解决的问题，确定模型。

需要解决什么问题

预测分类      分类（Classification）  比如预测泰坦尼克号的人的生存可能性

预测取值      回归（Regression）

发现结构      聚类（Clustering）  无监督学习

发现异常数据  异常检测（Anomaly Detection） 信用卡防欺诈

 ![](assets/002/01/02/02-1684140404880.png)


 ### 三、策略

策略:从假设空间众多的假设中选择到最优的模型的学习标准或规则。

要从假设空间中选择一个最合适的模型出来，需要解决以下问题:

（1）评估某个模型对单个训练样本的效果

（2）评估某个模型对训练集的整体效果

（3）评估某个模型对包括训练集、预测集在内的所有数据的整体效果

定义几个指标用来衡量上述问题:

损失函数:0-1损失函数、平方损失函数、绝对损失函数、对数损失函数等

风险函数:经验风险、期望风险、结构风险

基本策略：

经验风险最小（EMR :Empirical Risk Minimization)

结构风险最小（SRM : Structural Risk Minimization)

![](assets/002/01/02/02-1684140698471.png)


## 损失函数



![](assets/002/01/02/02-1684141107815.png)


### 平方损失函数

![](assets/002/01/02/02-1684144349894.png)


![](assets/002/01/02/02-1684144472623.png)


###  对数损失函数

（四）对数损失函数(Logarithmic LF)或对数似然损失函数(log-likehood loss function)：

对数函数具有单调性，在求最优化问题时，结果与原始目标一致。可将乘法转化为加法，简化计算：

L(Y，P(Y∣X))= -logP(Y∣X)

### 指数损失函数

（五）指数损失函数(Exponential LF)：

单调性、非负性的优良性质，使得越接近正确结果误差越小        

L(Y,f(x))=


![](assets/002/01/02/02-1684144575133.png)


### （六）折叶损失函数(Hings LF):

     也称铰链损失，对于判定边界附近点的惩罚力度较高，常见于SVM

     L(f(x))=max(0,1-f(x))

 

不同的损失函数有不同的特点，适用于不同的场景

0-1：理想状况模型
Log：逻辑回归、交叉熵
Squared:线性回归 （平方）
Exponential:AdaBoosting （对数）
Hinge:SVM、soft margin （折叶）


## 经验风险

内容介绍：

一、经验风险Vs风险函数

二、经验风险的问题

三、结构风险

### 一、经验风险Vs风险函数

1.经验风险( Empirical Risk) :

损失函数度量了单个样本的预测结果,要想衡量整个训练集的预测值与真实值的差异,将整个训练集所有记录均进行一-次预测 ,求取损失函数，将所有值累加,即为经验风险。经验风险越小说明模型f(x)对训练集的拟合程度越好。

 

2.风险函数( Risk Function) :

 又称期望损失、期望风险。所有数据集(包括训练集和预测集，遵循联合分布P(X,Y) )的损失函数的期望值。

 

3.经验风险和期望风险的对比

期望风险是模型对全局(所有数据集)的效果;经验风险是模型对局部(训练集)的效果

期望风险往往无法计算,即联合分布P(X,Y)通常是未知的;经验风险可以计算

当训练集足够大时，经验风险可以替代期望风险，即局部最优代替全局最优



![](assets/002/01/02/02-1684145001737.png)