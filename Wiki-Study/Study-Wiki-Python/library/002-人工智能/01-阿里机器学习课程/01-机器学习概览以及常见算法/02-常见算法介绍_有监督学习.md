# 常见算法介绍

1 课程纲要
（1）介绍算法的常见分类

（2）介绍有监督学习算法，重点介绍 KNN、ID3

（3）介绍无监督学习算法,重点介绍 Apriori、K- Means

（4）介绍其他常见的算法

 

2 学习目标
1了解无监督学习与有监督学习

2掌握 KNN、ID3 分类算法

3掌握 Apriori、K-Means 算法

4了解集成学习等其他算法

## 常见算法分类

常见算法分类

内容简介：

1 算法

2 有身高预测体重

3 常见机器学习算法分类


### 1 算法

![](assets/002/01/01/02-1683878142445.png)


1 算法

算法:是利用计算机解决特定问题的处理步骤,是有限操作的集合。

以机器学习下西洋跳棋为例,其问题描述如下:

#### 任务T :下西洋跳棋

性能标准P :赢棋的概率

经验E :和自己对弈

目标函数: V

通过将棋盘上的棋子进行评分,并将棋子及所在的位置和一个目标函数V建立联系,该目标函数V的值可以描述当前棋盘局面。在棋子、局面和性能标准P之间建立联系,将P 描述成一个和棋子、局面相关的函数，根据已有的数据(经验E )去求解P中各相关参数的最优值。

机器学习的思路:  b1->b2->b3-> ...>.->END

■任务T :下西洋跳棋

■性能标准P :赢棋的概率              

■经验E:和自己对弈胜100  V(b)=100

■确定目标函数: V 平0   V(b)=0

负-100   V(b)=-100

V(b)=V(b' )

棋局状态b评估:              

■X1 :棋盘上黑子的个数

■X2 :棋盘上红子的个数

■X3: 棋盘上黑王的个数输入棋谱或者自己和自己下很多

■X4:棋盘上红王的个数 盘,可以求出w0、w1.....w6

■X5:被红子威胁的黑子个数        

■X6:被黑子威胁的红子个数

V(b)=w0+w1*X1 +... +w6*X6


#### 身高预测体重

![](assets/002/01/01/02-1683878255263.png)



![](assets/002/01/01/02-1683878283073.png)

![](assets/002/01/01/02-1683878495703.png)


### 3 常见机器学习算法分类

监督式学习 、无监督学习 、半监督学习

学习样本中有结果标记 学习样本中无结果标记  学习样本中部分记

录有结果标记。

![](assets/002/01/01/02-1683878629157.png)


（1）有监督学习

有监督学习( Supervised learning ) : 利用-组已知类别的样本来训练模型，使其达到性能要求。特点 为输入数据(训练数据)均有一一个明确的标识或结果(标签)。即我们提供样例"教"计算机如何学习。

![](assets/002/01/01/02-1683878647733.png)



![](assets/002/01/01/02-1683878696732.png)


 （2）无监督学习

![](assets/002/01/01/02-1683878900661.png)

无监督学习( Unsupervised learning ) :从无标记的训练数据中推断结论。其特点为输入数据(训练数据)不存在明确的标识或结果(标签)。

常见的无监督学习为聚类，即发现隐藏的模式或者对数据进行分组。即计算机根据我们提供的材料"自动”学习， 给定数据,寻找隐藏的结构或模式。


一句话说明有监督学习，无监督学习：

平时的做题训练(直到让你做对)、属于有监督
考试：属于无监督


## 有监督学习算法（上）




内容简介：

1、 什么是有监督学习算法

2 、分类: Classification

3 、回归: Regression

4 、分类算法

5 、KNN

6 、实现步骤图示

7 、实现伪码

8、 KNN优缺点


### 1、 什么是有监督学习算法


有监督学习( Supervised learning ) :利用一-组已知类别的样本来训练模型，使其达到性能要求。

特点为输入数据(训练数据)均有一个明确的标识或结果(标签)。即我们提供样例"教”计算机如何学习。

![](assets/002/01/01/02-1683879132565.png)

### 分类算法 Classification

![](assets/002/01/01/02-1683879160323.png)

### 回归 Regression

![](assets/002/01/01/02-1683879507536.png)



### 分类算法



![](assets/002/01/01/02-1683879540475.png)

分类算法通过对已知类别训练集的分析,从中发现分类规则,以此预测新数据的类别。分类算法的应用非常广泛,银行风险评估、客户类别分类、文本检索和搜索引擎分类、安全领域中的入侵检测以及软件项目中的应用等。

按原理分类

■基于统计的:如贝叶斯分类

■基于规则的:如决策树算法

■基于神经网络的:神经网络算法

■基于距离的: KNN ( K最近邻)

常用评估指标:





■精确率:预测结果与实际结果的比例

■召回率:预测结果中某类结果的正确覆盖率

■F1-Score :统计量,综合评估分类模型,取值0-1之间

 


### KNN 分类算法之一

![](assets/002/01/01/02-1683879699484.png)



KNN : k-Nearest Neighbour ,分类算法中最简单的算法之一，其核心思想是如果离某一个样本最近的 k 个本中的大多数属于某一个类别,则该样本也属于这个类别，并具有这个类别上样本的特性。KNN 不但可以预测分类，还可以做回归分析(预测具体的值)。

有N个已知分类结果的样本点,对新记录 r 使用 KNN 将其分类的步骤:

Step 1:确定 k 值，确定计算距离的公式,比如欧氏距离

Step2:计算 r 和其他样本点之间的距离 di;r,其中i∈(1,N)

Step 3 :得到目前和 r 最接近的 k 个样本,作为 KNN 距的训练样本

Step4 :将 k 个样本中最多归属类别的分类标签赋予新记录 r ,分类结束



#### 实现步骤

![](assets/002/01/01/02-1683879918766.png)


![](assets/002/01/01/02-1683879949331.png)


![](assets/002/01/01/02-1683879986387.png)


实现的伪码


![](assets/002/01/01/02-1683880012611.png)


#### knn 优缺点

![](assets/002/01/01/02-1683880043316.png)


8 、KNN 优缺点
优点:

原理简单，容易理解,容易实现

重新训练代价较低

时间、空间复杂度取决于训练集(一般不算太大)

缺点:

KNN 属于 lazy-learning  算法,得到结果的及时性差

k 值对结果影响大(试想一下 k=1 和 k=N 的极端情况)

不同类记录相差较大时容易误判

样本点较多时,计算量较大

相对于决策树，结果可解释性不强



## 有监督学习算法（下）



内容简介：

1 决策树:构建流程

2 熟悉数据。明确目标

3 信息熵

4 信息增益和特征选择

5 构建决策树

6 第一级特征选择

7 ID3系列算法

8 CART

9 其他常见有监督学习算法


### 决策树:构建流程

![](assets/002/01/01/02-1683880467644.png)

1 决策树:构建流程
（1）准备工作

明确自变量和因变量确定信息度量的方式确定终止条件

（2）选择特征

得到当前待处理子集计算所    有特征信息度量得到当前最佳分类特征

（3）创建分支

根据选中特征将当前记录分成不同分支，分支个数取决于算法

（4）是否终止

判断是否满足终止条件满足则退出循环不满足则继续递归调用

（5）结果生成

判断是否需要剪枝需要则进行适当修剪不需要则为最终结果

观察数据,明确自变量和因变量

### 熟悉数据。明确目标



![](assets/002/01/01/02-1683880564246.png)

因变量：是否买电脑; 自变量 ： 年龄 、收入 。。。。 
这里选择 ： 熵

2 熟悉数据。明确目标
■自变量

■因变量

明确信息度量方式:信息增益

■熵

■基尼系数

明确分支终止条件

■纯度

■记录条数

■循环次数

根据电脑购买记录,对购买者建模。该模型可以基于客户的一些信息预测他是否会购买电脑。


### 信息熵

![](assets/002/01/01/02-1683881141225.png)

3 信息熵

■信息论里的概念,香农提出

■描述混乱程度的度量

■取值范围 0~1 ,值越大,越混乱

■计算公式:

图片1范范.png

有一堆苹果和梨共100个,随机拿出一个,拿出的是哪种?

■50个苹果+ 50个梨子

■0个苹果+ 100个梨子

■80个苹果+ 20个梨子

E1=-50/100*log(50/100,2) - 50/100*log(50/100,2) = 1

E2=-100/100*log(100/100,2)=0

E3= -20/100*log(20/100,2) - 80/100*log(80/100,2) = 0.722



### 信息增益和特征选择

信息增益

■信息是确定性的增加

■从一个状态到另一一个状态信息的变化

■信息增益越大,对确定性贡献越大

搜集了几种植物果实的颜色和味道,根据

这两个信息确定是否为水果?

不考虑任何特征,直接去估计结果:

其中,两个是水果,两个不是水果,概率均为2/4 :

E= -2/4*log(2/4,2) - 2/4*log(2/4,2)=1

考虑以颜色为参考信息,判断是否为水果:

其中,红色的有3个,2个是水果,一一个不是,绿色的都不是,概率

分别为: 2/3,1/3以及1, 0

E=3/4*(-2/3*log(2/3,2) - 1/3*log(1/3,2))

+ 1/4*(-1*log(1,2)) = 0.689

考虑以味道为参考信息,判断是否为水果:

其中,甜味的2个,全是水果,不甜的2个,全不是水果,概率分别

为:1,0以及0,1

E=2/4*(- 2/2*log(2/2,2)) + 2/4*(- 2/2*log(2/2,2)) = 0

信息增益:

颜色: 1-0.689=0.311

味道: 1-0=1

整体的熵- 各个特征的熵= 各个特征的信息增益

![](assets/002/01/01/02-1683881511553.png)



### 构建决策树

![](assets/002/01/01/02-1683881561430.png)

### 第一级特征选择


计算整体的熵:购买: 9例，未购买: 5例

计算年龄的熵

计算收入的熵

计算单身的熵

计算信用的熵

 ![](assets/002/01/01/02-1683885852725.png)



 *** 可以看到 年龄的信息增益最大，则选择年龄为第一级特征 ***



 ![](assets/002/01/01/02-1684120816418.png) 






#### 第一级特征年龄分支


![](assets/002/01/01/02-1684120865156.png)


### 第二特征选择


#### 中年分支


中年分支已经纯度都是0，那么则不需要继续分支

![](assets/002/01/01/02-1684120997482.png)



#### 老年分支

![](assets/002/01/01/02-1684121669638.png)


### 构建决策树


![](assets/002/01/01/02-1684121684050.png)


### 生成决策树


![](assets/002/01/01/02-1684121887714.png)


### ID3 算法 (以上的基于熵 基于规则的决策树分析算法 就是用的id3 )


ID3 ( Iterative Dichotomiser 3，迭代树三代)

■核心是信息熵,根据信息增益决定树的节点

■存在以下问题:

V 信息度量不合理:倾向于选择取值多的字段

V 输入类型单一:离散型

V 不做剪枝，容易过拟合

C4.5 :和ID3相比的改进:

V 用信息增益率代替信息增益

V 能对连续属性进行离散化，对不完整数据进行处理

V 进行剪枝

C50 : C4.5相比的改进:

V 使用了 boosting

v 前修剪、后修剪

### CART （基于基尼系数的就是cart 这种了）

CART ( Classification and Regression Tree )

■核心是基尼系数( Gini )

■分类是二叉树

■支持连续值和离散值

■后剪枝进行修剪

■支持回归,可以预测连续值



###  其他常见有监督学习算法分类算法:



■KNN ( K最近邻，K-Nearest Neighbour)

■NB (朴素贝叶斯 ，Naive Bayes )

■DT (决策树, Decision Tree ) : C45、CART

■SVM (支持向量机, Support Vector Machine )

回归预测:

■线性回归( Linear Regression )

■逻辑回归( Logistic Regression )

■岭回归( Ridge Regression )

■拉索回归( LASSO Regression )

![](assets/002/01/01/02-1684122127267.png)