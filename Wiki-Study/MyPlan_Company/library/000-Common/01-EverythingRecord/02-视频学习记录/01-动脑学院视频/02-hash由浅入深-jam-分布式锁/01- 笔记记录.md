# 

## 

> 1 往期录播
![](assets/000/01/02/01/02/01-1611368973499.png)


> 2课程安排

![](assets/000/01/02/01/02/01-1611369003753.png)

## 开始


### 开始一个场景问题；

![](assets/000/01/02/01/02/01-1611369236963.png)


> 1 这里模拟高并发同时产生订单编号，遇到的的问题

* 1 订单服务类代码

![](assets/000/01/02/01/02/01-1611369434691.png)



* 订单编号实现类代码

![](assets/000/01/02/01/02/01-1611369732784.png)

* 2 执行

![](assets/000/01/02/01/02/01-1611369507059.png)


> 2 可以看到 并不能实现唯一订单编号


![](assets/000/01/02/01/02/01-1611369805523.png)



> 2.1 所以 这里尝试第一种方案，加锁 (单机模式可以解决)


![](assets/000/01/02/01/02/01-1611370072710.png)

最终 释放锁 

![](assets/000/01/02/01/02/01-1611370107158.png)

这种方式针对 刚才那种200 并发貌似是尅解决了问题，但是假如数据量上升到万级别，那单台服务器肯定是有够呛， 

tomcat 的话 上万估计 不太行了

所以这个时候可以做负载均衡 ，多台服务器

![](assets/000/01/02/01/02/01-1611370516218.png)

* 但是这种情况可以解决订单问题吗 

![](assets/000/01/02/01/02/01-1611370603701.png)



* 答案显而易见！ 是不能的，即便是加了锁， 因为加锁也只是对他自己的服务加锁了


![](assets/000/01/02/01/02/01-1611370631073.png)



> 2.2 分布式 环境下 ，产生了问题，问题在哪？ 订单编编号不共享，也就是你把生成订单编号id 的服务单独提出来，单独放到一个服务中吗？ 类似于这种意思，但是这里利用单例模式 模拟这种情况（但是因为刚才上代码中内部线程中是new 对象的，所以 在分布式情况下，利用单例模式是解决不了问题的。因为单例对象有多个）

![](assets/000/01/02/01/02/01-1611370907840.png)


这个时候整体架构如下；

![](assets/000/01/02/01/02/01-1611371050091.png)



** 但是问题解依然存在，为什么？ 不是已经是单例了吗，但是不要忘了，订单服务中的确也加锁了，但是加的锁不是同一个锁**


![](assets/000/01/02/01/02/01-1611371419932.png)


> 2.2 【引入分布式锁】所以，解决分布式环境下，单例模式也会出现的线程问题，怎么解决？  将锁加到单例对象上！！！！！！


如下图，将锁加到单例上  （问题能解决，但是会造成性能问题，相当于分布式没有太大意义，所以这里就引入到了 分布式锁）

![](assets/000/01/02/01/02/01-1611371506846.png)


### 分布式锁

![](assets/000/01/02/01/02/01-1611371713093.png)

分布式锁作用：

![](assets/000/01/02/01/02/01-1611371785680.png)


> 1 锁的三特性


![](assets/000/01/02/01/02/00-1611371903919.png)

* 2 我们已知的实现排他性的计算机技术

![](assets/000/01/02/01/02/00-1611372034907.png)

* 3 在这些技术中，都有不一样的缺点，但是zookeeper 可以胜任这项工作

![](assets/000/01/02/01/02/01-1611372167178.png)

zookeeper 是dubbo 的注册中心


### zookeeper 的简介




![](assets/000/01/02/01/02/01-1611372555224.png)


![](assets/000/01/02/01/02/01-1611372718621.png)

![](assets/000/01/02/01/02/01-1611372756680.png)



* zookeeper 节点类型


![](assets/000/01/02/01/02/01-1611373014689.png)

特性：同一个znode下的子节点，节点名称必须唯一


### zookeeper 典型场景


![](assets/000/01/02/01/02/01-1611373474325.png)


> 1 所以 这里主要介绍怎么用zookeeper 实现分布式锁 

特性：统一父节点下的节点名称唯一

#### zookeeper 实现分布式锁逻辑1

![](assets/000/01/02/01/02/01-1611373706783.png)


* 分布式锁 订单服务类实现

* zookeeper 节点的一部分代码


![](assets/000/01/02/01/02/01-1611374705913.png)
![](assets/000/01/02/01/02/01-1611374766092.png)


* 分布式锁实现部分代码

![](assets/000/01/02/01/02/01-1611374412334.png)
![](assets/000/01/02/01/02/01-1611374458102.png)
![](assets/000/01/02/01/02/01-1611374531273.png)



* 订单实现类

![](assets/000/01/02/01/02/01-1611373969632.png)
![](assets/000/01/02/01/02/01-1611374044304.png)


* 问题是解决了，但是会有另外一个问题资源消耗

![](assets/000/01/02/01/02/01-1611374297713.png)

#### zookeeper 实现分布式锁逻辑2 (是为了解决上述问题)


![](assets/000/01/02/01/02/01-1611375065513.png)



* 这里代码就不就粘贴了 ，人家没想让截图啊！！！ 不过答题思路 就是 ，按照顺序，生成节点，谁拿到的锁是第一个节点，那就谁拿到了锁