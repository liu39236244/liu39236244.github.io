# hive 编程指南

## hive 出现的原因

![hive出现的原因](assets/001/20180509-f3b906f4.png)  


* hive 的局限性
本身地城hadoop 的局限性决定了hive能胜任的工作。不支持纪录级别的更新、插入、或者删除操作。并且hive不支持事务，启动过程需要消耗更长时间。而且hive 不支持oltp（联机事务处理），更接近olap 联机分析技术。如果需要对大规模数据实用oltp的话，需要使用nosql 数据库，比如hbase、cassandra数据库。
因此hive适合做数据仓库维护海量数据，进行数据挖掘，形成报告意见！
* 特性
  hive 的hql语言并不符合ANSIsql标准，与 mysql oracel SQL server 支持的sql方言存在很多方面的差异，（hiveql与mysql提供的最接近）

* Map reduce
  map 会把大写字母转化小写，看成一个

![使用OLAP功能，的使用设定](assets/001/20180509-e5142ee9.png)  

## hive的命令行

![hive 命令行 cli使用的集中方式](assets/001/20180509-182260c4.png)  


## hbase

hive 不支持事务，而且也不支持行级别的更改，所以 出现hbase ，就是谷歌bigtable论文演化而来的。但并不没实现所有特性。
hbae:支持 行级别更改，支持行级事务，（不支持多行事务），快速查询相应。
* 最重要的就是列存储，列组成列簇。列簇在分布式系统中物理上是存才一块的。所以如果查询涉及到的是所有列的一个子集的话，查询会变得很快，因为不需要读取每一行且丢弃大部分列，而是只需要读取需要的列。

* 可以 像 键-值 存储数据，每一行都有唯一的键提供非常快的速度读取这一行数据，与这一行数据所对应的列簇，每个列保存了多个版本的数据，以至于可以进行数据恢复，保存的版本可以进行配置保留的版本数

### hbase 与hadop 关系

hbase 使用hdfs （或者其他分布式存储文件系统）持久化存储数据，为了提供行级别的快速更新与查询，hbase也是用了内存缓存技术对数据和本地文件进行追加数据更新与更新操作日志，持久化文件将会定期进行数据更新，hbase没有提供sql语言操作，但是hive 可以与hbase结合


### Cascading 与Crunch 以及其他

apache hadoop 生态系统提供了其他的高级语言，提供了不错的抽象减少底层的编码工作，所有都是jvm 库，可用于java 、clojure、Scala、jRuby、Groovy 和jython，不像hive pig 使用自己的语言工具。

使用这些编程语言有利弊，熟悉sql的非程序员使用的话可能不容易上手，对于开发工程师来说，这些语言提供了图灵的完全的编程语言的控制，hive和pig都是图灵完全性的（图灵完全性是指：具有无线存储能力的通用物理机械或者编程语言），所以hive没有提供的，我们就学者用java或者scala 进行开发吧

#### hadoop 之上的集中高级语言
略
![hadoop之上的高级语言](assets/001/20180514-3d8b484c.png)  


#### hadoop是面向批处理系统，所以存在合适的事件流处理的分布式的工具，事件流近乎事实处理，一下给出了集中工具。

#### 没有使用mapreduce 的处理工具

![](assets/001/20180514-201584e0.png)  

#### 当不需要完整集群
跑不需要完整集群，或者数据量不大或者对时间要求没那么苛刻的话，还有不少可选工具可以轻松处理原型算法或者对数据子集进行探索

![其他处理语言与工具](assets/001/20180514-e765776b.png)  


## 第二章基础操作

这里提供了实现配置好的hadoop虚拟机，可以作为参考

![实现的虚拟机](assets/001/20180514-77a1612d.png)  


### hadoop 安装过程记录

hadoop 如果是本地模式的话，会在统一进程加载maporeduce组件，但是如果实在分布式，或者为分布式的但台机子的话，会用jobtracker 启动一个或者多个不同的进程。
跑jar 文件

hadoop jar /jar路径/abc.jar 类名 参数1 参数2 参数n


* 另外对于比较大的文件hadoop 并没有提供一些 查看more、head 、-tail等命令，但是可以通过管道 发送传递 ：
例如： hadoop dfs -cat 文件.后缀 | more


### hive 内部是什么

hive 内部有三个重要的部分。主要部分是java代码本身。
hive  $HIVE_HOME/lib  中有实现功能的jar包
hive $HIVE_HOME/bin 包含许多可执行文件命令

hive 最主要的是 提供了 thrift 功能提供了能访问远程计算机的进程的功能。也提供了jdbc odbc 访问hive，都是基于thrift。
hive 客户端都需要一个元数据服务metastoreservice，hive 使用这个服务来存储表模式信息和元数据信息。
* 默认情况下 hive 提供 derby sql服务，提供有限的单进程存储服务，例如：使用hive 的cli的时候，不能同时两个。

#### hive 本地模式

本地模式所有提及的数据都是本地文件系统而不是分布式，没有服务在运行。用户的job 在同一个jvm 实例中执行所有任务。
用户关$HIVE_HOME/conf/下面的hive-site.xml,管这个就行了 ，如过没有的话自己创建一个

![本地的worldcount 的执行图](assets/001/20180514-6c82b999.png)  

* 本地模式下面hive 配置

![本地模式下面的hive 的配置](assets/001/20180514-51904e72.png)  
![hive配置 下](assets/001/20180514-bb982285.png)  
